{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# statistics for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_train = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_training.csv')\n",
    "data_pan15_test = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train = data_pan15_train.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()\n",
    "combined_pan15_test = data_pan15_test.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train_stats = pd.DataFrame()\n",
    "combined_pan15_train_stats['total_word_count'] = combined_pan15_train['text'].apply(lambda x: len(x.split()))\n",
    "combined_pan15_train_stats['unique_word_count'] = combined_pan15_train['text'].apply(lambda x: len(set(x.split())))\n",
    "combined_pan15_train_stats['average_word_length'] = combined_pan15_train['text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "combined_pan15_train_stats['flesh_readability'] = combined_pan15_train['text'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_test_stats = pd.DataFrame()\n",
    "combined_pan15_test_stats['total_word_count'] = combined_pan15_test['text'].apply(lambda x: len(x.split()))\n",
    "combined_pan15_test_stats['unique_word_count'] = combined_pan15_test['text'].apply(lambda x: len(set(x.split())))\n",
    "combined_pan15_test_stats['average_word_length'] = combined_pan15_test['text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "combined_pan15_test_stats['flesh_readability'] = combined_pan15_test['text'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sten\\AppData\\Local\\Temp\\ipykernel_1516\\1029075606.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_pan15_train_stats.describe().T.round(3).to_latex( caption=\"PAN 15 AP task descriptive statistics\", label=\"tab:your_label\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{table}\\n\\\\centering\\n\\\\caption{PAN 15 AP task descriptive statistics}\\n\\\\label{tab:your_label}\\n\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n{} &  count &      mean &      std &      min &      25\\\\% &       50\\\\% &       75\\\\% &       max \\\\\\\\\\n\\\\midrule\\ntotal\\\\_word\\\\_count    &  152.0 &  1104.717 &  336.304 &  332.000 &  954.000 &  1101.000 &  1285.250 &  1868.000 \\\\\\\\\\nunique\\\\_word\\\\_count   &  152.0 &   623.191 &  181.482 &  227.000 &  515.000 &   619.000 &   731.250 &  1106.000 \\\\\\\\\\naverage\\\\_word\\\\_length &  152.0 &     5.623 &    0.875 &    4.031 &    4.851 &     5.583 &     6.356 &     7.436 \\\\\\\\\\nflesh\\\\_readability   &  152.0 &    68.042 &   13.843 &   35.440 &   59.192 &    69.260 &    78.575 &    96.990 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pan15_train_stats.describe().T.round(3).to_latex( caption=\"PAN 15 AP task descriptive statistics\", label=\"tab:your_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sten\\AppData\\Local\\Temp\\ipykernel_1516\\2196114918.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_pan15_test_stats.describe().T.round(3).to_latex()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n{} &  count &      mean &      std &      min &      25\\\\% &       50\\\\% &       75\\\\% &       max \\\\\\\\\\n\\\\midrule\\ntotal\\\\_word\\\\_count    &  142.0 &  1105.127 &  361.950 &  281.000 &  920.500 &  1126.500 &  1313.250 &  1983.000 \\\\\\\\\\nunique\\\\_word\\\\_count   &  142.0 &   611.155 &  195.167 &   94.000 &  487.250 &   603.500 &   723.000 &  1090.000 \\\\\\\\\\naverage\\\\_word\\\\_length &  142.0 &     5.603 &    0.840 &    4.004 &    4.852 &     5.671 &     6.288 &     7.556 \\\\\\\\\\nflesh\\\\_readability   &  142.0 &    67.503 &   13.757 &   38.180 &   55.995 &    67.195 &    79.820 &    97.400 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pan15_test_stats.describe().T.round(3).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_pan15_train = pd.read_csv(r\"C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\PAN 15\\pan15-author-profiling-training-dataset-2015-04-23\\pan15-author-profiling-training-dataset-english-2015-04-23\\truth.txt\",\n",
    "                          delimiter=':::', engine='python', header=None)\n",
    "truth_pan15_train.columns = ['author', 'gender', 'age', 'pers1', 'pers2', 'pers3', 'pers4', 'pers5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_pan15_test = pd.read_csv(r\"C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\PAN 15\\test_data\\pan15-author-profiling-test-dataset2-english-2015-04-23\\truth.txt\",\n",
    "                          delimiter=':::', engine='python', header=None)\n",
    "truth_pan15_test.columns = ['author', 'gender', 'age', 'pers1', 'pers2', 'pers3', 'pers4', 'pers5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan 15 training gender:\n",
      "M    76\n",
      "F    76\n",
      "Name: gender, dtype: int64\n",
      "Pan 15 training age:\n",
      "25-34    60\n",
      "18-24    58\n",
      "35-49    22\n",
      "50-XX    12\n",
      "Name: age, dtype: int64\n",
      "Pan 15 test gender:\n",
      "F    71\n",
      "M    71\n",
      "Name: gender, dtype: int64\n",
      "Pan 15 test age:\n",
      "25-34    58\n",
      "18-24    56\n",
      "35-49    20\n",
      "50-XX     8\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Pan 15 training gender:\")\n",
    "print(truth_pan15_train['gender'].value_counts())\n",
    "print(\"Pan 15 training age:\")\n",
    "print(truth_pan15_train['age'].value_counts())\n",
    "print(\"Pan 15 test gender:\")\n",
    "print(truth_pan15_test['gender'].value_counts())\n",
    "print(\"Pan 15 test age:\")\n",
    "print(truth_pan15_test['age'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt1.csv')\n",
    "df_gemini = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini1.csv')\n",
    "df_llama = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_stats = pd.DataFrame()\n",
    "df_gpt_stats['total_word_count'] = df_gpt['text'].apply(lambda x: len(x.split()))\n",
    "df_gpt_stats['unique_word_count'] = df_gpt['text'].apply(lambda x: len(set(x.split())))\n",
    "df_gpt_stats['average_word_length'] = df_gpt['text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "df_gpt_stats['flesh_readability'] = df_gpt['text'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_word_count</th>\n",
       "      <td>250.0</td>\n",
       "      <td>272.056</td>\n",
       "      <td>15.896</td>\n",
       "      <td>222.000</td>\n",
       "      <td>259.000</td>\n",
       "      <td>273.000</td>\n",
       "      <td>283.000</td>\n",
       "      <td>303.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_word_count</th>\n",
       "      <td>250.0</td>\n",
       "      <td>181.268</td>\n",
       "      <td>8.988</td>\n",
       "      <td>155.000</td>\n",
       "      <td>176.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>185.000</td>\n",
       "      <td>217.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_word_length</th>\n",
       "      <td>250.0</td>\n",
       "      <td>5.633</td>\n",
       "      <td>0.144</td>\n",
       "      <td>5.314</td>\n",
       "      <td>5.516</td>\n",
       "      <td>5.625</td>\n",
       "      <td>5.747</td>\n",
       "      <td>5.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh_readability</th>\n",
       "      <td>250.0</td>\n",
       "      <td>-146.659</td>\n",
       "      <td>103.824</td>\n",
       "      <td>-235.060</td>\n",
       "      <td>-211.970</td>\n",
       "      <td>-193.790</td>\n",
       "      <td>-174.160</td>\n",
       "      <td>46.300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count     mean      std      min      25%      50%  \\\n",
       "total_word_count     250.0  272.056   15.896  222.000  259.000  273.000   \n",
       "unique_word_count    250.0  181.268    8.988  155.000  176.000  180.000   \n",
       "average_word_length  250.0    5.633    0.144    5.314    5.516    5.625   \n",
       "flesh_readability    250.0 -146.659  103.824 -235.060 -211.970 -193.790   \n",
       "\n",
       "                         75%      max  \n",
       "total_word_count     283.000  303.000  \n",
       "unique_word_count    185.000  217.000  \n",
       "average_word_length    5.747    5.913  \n",
       "flesh_readability   -174.160   46.300  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt_stats.describe().T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gemini_stats = pd.DataFrame()\n",
    "df_gemini_stats['total_word_count'] = df_gemini['text'].apply(lambda x: len(x.split()))\n",
    "df_gemini_stats['unique_word_count'] = df_gemini['text'].apply(lambda x: len(set(x.split())))\n",
    "df_gemini_stats['average_word_length'] = df_gemini['text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "df_gemini_stats['flesh_readability'] = df_gemini['text'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sten\\AppData\\Local\\Temp\\ipykernel_1516\\3574736219.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_gemini_stats.describe().T.round(3).to_latex()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n{} &  count &     mean &     std &      min &     25\\\\% &      50\\\\% &     75\\\\% &      max \\\\\\\\\\n\\\\midrule\\ntotal\\\\_word\\\\_count    &  137.0 &  147.985 &  45.447 &   96.000 &  122.00 &  130.000 &  152.00 &  382.000 \\\\\\\\\\nunique\\\\_word\\\\_count   &  137.0 &  101.861 &  24.052 &   76.000 &   88.00 &   92.000 &  105.00 &  224.000 \\\\\\\\\\naverage\\\\_word\\\\_length &  137.0 &    5.439 &   0.376 &    4.395 &    5.26 &    5.475 &    5.68 &    6.191 \\\\\\\\\\nflesh\\\\_readability   &  137.0 &    5.330 &  27.537 & -168.410 &   -2.26 &    6.180 &   18.53 &   65.760 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gemini_stats.describe().T.round(3).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama_stats = pd.DataFrame()\n",
    "df_llama_stats['total_word_count'] = df_llama['text'].apply(lambda x: len(x.split()))\n",
    "df_llama_stats['unique_word_count'] = df_llama['text'].apply(lambda x: len(set(x.split())))\n",
    "df_llama_stats['average_word_length'] = df_llama['text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "df_llama_stats['flesh_readability'] = df_llama['text'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sten\\AppData\\Local\\Temp\\ipykernel_1516\\3312740351.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_llama_stats.describe().T.round(3).to_latex()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n{} &  count &     mean &     std &      min &      25\\\\% &      50\\\\% &      75\\\\% &     max \\\\\\\\\\n\\\\midrule\\ntotal\\\\_word\\\\_count    &  189.0 &  285.016 &  94.961 &   50.000 &  231.000 &  285.000 &  356.000 &  633.00 \\\\\\\\\\nunique\\\\_word\\\\_count   &  189.0 &  147.709 &  45.010 &   39.000 &  119.000 &  148.000 &  175.000 &  324.00 \\\\\\\\\\naverage\\\\_word\\\\_length &  189.0 &    4.938 &   0.709 &    3.435 &    4.477 &    4.893 &    5.308 &    8.44 \\\\\\\\\\nflesh\\\\_readability   &  189.0 &   16.119 &  82.482 & -355.170 &  -12.780 &   54.490 &   70.190 &   98.51 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama_stats.describe().T.round(3).to_latex()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
