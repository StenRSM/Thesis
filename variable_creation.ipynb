{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the variables used in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_training = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_test = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan17_train = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_17_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan17_test = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_17_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan17_train = data_pan17_train.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first'\n",
    "}).reset_index()\n",
    "combined_pan17_test = data_pan17_test.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003de26f870d27f79887272a1eb3612</td>\n",
       "      <td>One to watch … \\nAvailable on 10th Feb. https:...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102cce280df9f6e0e78bfdd266f1abb5</td>\n",
       "      <td>Are we living in a holographic universe? New s...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10488b3700fa9d2db22961ab064e4d38</td>\n",
       "      <td>Museum focus, but still great pieces of advice...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1064bd0b78f14bea5b851e2a995dd4e5</td>\n",
       "      <td>Best half time show EVER! @jannarden  not the ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106aa0abb81873d09028b01658c37611</td>\n",
       "      <td>Does this mean @WaitakereUnited are top of the...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>ffa8289a14683e00a607a2d9bb5d1367</td>\n",
       "      <td>@LauraAnthony7 @UCBerkeley eooks likes lynch m...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>ffbd53773c792831d5b6322b775faa3a</td>\n",
       "      <td>@groubes such a classy player! Was awesome to ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>ffc349a1e4c9a3b37fd8798e82d703a2</td>\n",
       "      <td>Great weekend spent with family! Thoroughly en...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>fff01fe00dae086650e48f265468e483</td>\n",
       "      <td>@SavageFc602 @TellEmSteveDave he IS the disord...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>fff1359e0dc1eba31a10120bf16834b7</td>\n",
       "      <td>@HuntersRL He's a lovely tall drink of water. ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                author  \\\n",
       "0     1003de26f870d27f79887272a1eb3612   \n",
       "1     102cce280df9f6e0e78bfdd266f1abb5   \n",
       "2     10488b3700fa9d2db22961ab064e4d38   \n",
       "3     1064bd0b78f14bea5b851e2a995dd4e5   \n",
       "4     106aa0abb81873d09028b01658c37611   \n",
       "...                                ...   \n",
       "3595  ffa8289a14683e00a607a2d9bb5d1367   \n",
       "3596  ffbd53773c792831d5b6322b775faa3a   \n",
       "3597  ffc349a1e4c9a3b37fd8798e82d703a2   \n",
       "3598  fff01fe00dae086650e48f265468e483   \n",
       "3599  fff1359e0dc1eba31a10120bf16834b7   \n",
       "\n",
       "                                                   text  gender  \n",
       "0     One to watch … \\nAvailable on 10th Feb. https:...    male  \n",
       "1     Are we living in a holographic universe? New s...  female  \n",
       "2     Museum focus, but still great pieces of advice...  female  \n",
       "3     Best half time show EVER! @jannarden  not the ...  female  \n",
       "4     Does this mean @WaitakereUnited are top of the...    male  \n",
       "...                                                 ...     ...  \n",
       "3595  @LauraAnthony7 @UCBerkeley eooks likes lynch m...  female  \n",
       "3596  @groubes such a classy player! Was awesome to ...    male  \n",
       "3597  Great weekend spent with family! Thoroughly en...    male  \n",
       "3598  @SavageFc602 @TellEmSteveDave he IS the disord...  female  \n",
       "3599  @HuntersRL He's a lovely tall drink of water. ...  female  \n",
       "\n",
       "[3600 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pan17_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Character-based features\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def alphabetic_ratio(text):\n",
    "    alphabetic = sum(c.isalpha() for c in text)\n",
    "    return alphabetic/len(text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    upper = sum(c.isupper() for c in text)\n",
    "    return upper/len(text)\n",
    "\n",
    "def digit_ratio(text):\n",
    "    digit = sum(c.isdigit() for c in text)\n",
    "    return digit/len(text)\n",
    "\n",
    "def whitespace_ratio(text):\n",
    "    whitespace = sum(c.isspace() for c in text)\n",
    "    return whitespace/len(text)\n",
    "\n",
    "def tab_ratio(text):\n",
    "    tabs = text.count('\\t')\n",
    "    return tabs/len(text)\n",
    "\n",
    "def letter_ratio(text, letter):\n",
    "    text = text.lower()\n",
    "    letter_count = text.count(letter)\n",
    "    return letter_count/len(text)\n",
    "\n",
    "def specialcharacter_ratio(text, character):\n",
    "    spec_count = text.count(character)\n",
    "    return spec_count/len(text)\n",
    "\n",
    "# Word-based features\n",
    "def number_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n",
    "def word_length(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length/num_words\n",
    "\n",
    "def vocabulary_richness(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_uniq_words = len(set(words))\n",
    "    return num_uniq_words/num_words\n",
    "\n",
    "def long_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    long_words_list = [word for word in words if len(word) > 6]\n",
    "    return len(long_words_list)/len(words)\n",
    "\n",
    "def short_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words_list = [word for word in words if 1 <= len(word) <= 3]\n",
    "    return len(short_words_list)/len(words)\n",
    "\n",
    "def legomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    return len(legomena)/len(words)\n",
    "\n",
    "def dislegomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    return len(dislegomena)/len(words)\n",
    "\n",
    "def yules_k(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    Vi = FreqDist(freq.values())\n",
    "    K = 10**4 * ((-N + sum(i**2 * Vi[i] for i in Vi))/N**2)\n",
    "    return K\n",
    "\n",
    "def simpson_d(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    if N < 2:\n",
    "        return 0\n",
    "    D = sum(fr * (fr - 1) / (N * (N - 1)) for fr in freq.values())\n",
    "    return D\n",
    "\n",
    "def sichel_s(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    S = len(dislegomena)/len(freq.values())\n",
    "    return S\n",
    "\n",
    "def honores_r(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if not words:\n",
    "        return 0\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    V = len(freq.values())\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    unique_count_ratio = len(legomena) / V if V > 0 else 0\n",
    "    if unique_count_ratio == 1 or N == 0:\n",
    "        return 0\n",
    "    R = (100*np.log(N)/(1-(len(legomena)/V)))\n",
    "    return R\n",
    "\n",
    "def entropy(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    E = -sum((fr / N) * np.log(fr/N) for fr in freq.values())\n",
    "    return E\n",
    "\n",
    "# Syntatic features\n",
    "def punctuations_ratio(text, punctuation):\n",
    "    punctuation_list = re.findall(punctuation, text)\n",
    "    return len(punctuation_list)/len(text)\n",
    "\n",
    "# Structural features\n",
    "def lines(text):\n",
    "    return len(text.split('\\n'))\n",
    "\n",
    "def sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "def paragraphs(text):\n",
    "    return len([par for par in text.split('\\n\\n') if par.strip()])\n",
    "\n",
    "def sentence_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(sent_tokenize(par)) for par in pars])\n",
    "\n",
    "def words_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(re.findall(r'\\b\\w+\\b', par)) for par in pars])\n",
    "\n",
    "def chars_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(par) for par in pars])\n",
    "\n",
    "def words_sentences(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return statistics.mean([len(word_tokenize(sentence)) for sentence in sents])\n",
    "\n",
    "def uppercase_start(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return (sum(1 for sentence in sents if sentence[0].isupper()) / len(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataframe, text_column):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Character-based features\n",
    "    features['total_characters'] = dataframe[text_column].apply(character_count)\n",
    "    features['ratio_alphabetic'] = dataframe[text_column].apply(alphabetic_ratio)\n",
    "    features['ratio_uppercase'] = dataframe[text_column].apply(uppercase_ratio)\n",
    "    features['ratio_digit'] = dataframe[text_column].apply(digit_ratio)\n",
    "    features['ratio_whitespace'] = dataframe[text_column].apply(whitespace_ratio)\n",
    "    features['ratio_tabspace'] = dataframe[text_column].apply(tab_ratio)\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for letter in letters:\n",
    "        features[letter+'_frequency'] = dataframe[text_column].apply(letter_ratio, args=(letter,))\n",
    "    special_characters = ['~', '@', '#', '$', '%', '^', '&', '*', '-', '_', '=', '+', '>', '<', '[', ']', '{', '}', '/', '\\\\', '|']\n",
    "    for character in special_characters:\n",
    "        features[character+'_frequency'] = dataframe[text_column].apply(specialcharacter_ratio, args=(character,))\n",
    "    \n",
    "    # Word-based features\n",
    "    features['total_words'] = dataframe[text_column].apply(number_words)\n",
    "    features['word_length'] = dataframe[text_column].apply(word_length)\n",
    "    features['vocabulary_richness'] = dataframe[text_column].apply(vocabulary_richness)\n",
    "    features['long_words'] = dataframe[text_column].apply(long_words)\n",
    "    features['short_words'] = dataframe[text_column].apply(short_words)\n",
    "    features['hapax_legomena'] = dataframe[text_column].apply(legomena)\n",
    "    features['hapax_dislegomena'] = dataframe[text_column].apply(dislegomena)\n",
    "    features['yules_k'] = dataframe[text_column].apply(yules_k)\n",
    "    features['simpson_d'] = dataframe[text_column].apply(simpson_d)\n",
    "    features['sichel_s'] = dataframe[text_column].apply(sichel_s)\n",
    "    #features['honore_r'] = dataframe[text_column].apply(honores_r)\n",
    "    features['entropy'] =  dataframe[text_column].apply(entropy)\n",
    "    # Brunet W?\n",
    "    # word length frequency distribution\n",
    "\n",
    "    \n",
    "    # Syntactic features\n",
    "    punctuations = [r\"’\", r\",\", r\"\\.\", r\":\", r\";\", r\"\\?\", r\"\\?{2,}\", r\"!\", r\"!{2,}\", r\"\\.{3}\"]\n",
    "    for punctuation in punctuations:\n",
    "        features[punctuation+\"_frequency\"] = dataframe[text_column].apply(punctuations_ratio, args=(punctuation,))\n",
    "\n",
    "    # Structural features\n",
    "    features['number_lines'] = dataframe[text_column].apply(lines)\n",
    "    features['number_sentences'] = dataframe[text_column].apply(sentences)\n",
    "    features['number_paragraphs'] = dataframe[text_column].apply(paragraphs)\n",
    "    features['sentences_per_paragraph'] = dataframe[text_column].apply(sentence_paragraph)\n",
    "    features['word_per_paragraph'] = dataframe[text_column].apply(words_paragraph)\n",
    "    features['character_per_paragraph'] = dataframe[text_column].apply(chars_paragraph)\n",
    "    features['word_per_sentence'] = dataframe[text_column].apply(words_sentences)\n",
    "    features['ratio_sentencestart_uppercase'] = dataframe[text_column].apply(uppercase_start)\n",
    "    features['gender'] = dataframe['gender']\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train = extract_features(data_pan15_training, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_test = extract_features(data_pan15_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_train = extract_features(data_pan17_train, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_test = extract_features(data_pan17_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan17_train_features = extract_features(combined_pan17_train, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan17_test_features = extract_features(combined_pan17_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_characters</th>\n",
       "      <th>ratio_alphabetic</th>\n",
       "      <th>ratio_uppercase</th>\n",
       "      <th>ratio_digit</th>\n",
       "      <th>ratio_whitespace</th>\n",
       "      <th>ratio_tabspace</th>\n",
       "      <th>a_frequency</th>\n",
       "      <th>b_frequency</th>\n",
       "      <th>c_frequency</th>\n",
       "      <th>d_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>\\.{3}_frequency</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>number_sentences</th>\n",
       "      <th>number_paragraphs</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>word_per_paragraph</th>\n",
       "      <th>character_per_paragraph</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>ratio_sentencestart_uppercase</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9587</td>\n",
       "      <td>0.761135</td>\n",
       "      <td>0.071242</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.158652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053927</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.024512</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>83.00</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>22.650602</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9713</td>\n",
       "      <td>0.755379</td>\n",
       "      <td>0.082879</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>0.155977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060743</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>13.862069</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9408</td>\n",
       "      <td>0.773278</td>\n",
       "      <td>0.068240</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060587</td>\n",
       "      <td>0.012117</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>61.00</td>\n",
       "      <td>753.5</td>\n",
       "      <td>4703.0</td>\n",
       "      <td>14.694215</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7483</td>\n",
       "      <td>0.755579</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.162903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058533</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.020847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>20.50</td>\n",
       "      <td>672.5</td>\n",
       "      <td>3740.5</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10457</td>\n",
       "      <td>0.776991</td>\n",
       "      <td>0.058334</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.145931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>10457.0</td>\n",
       "      <td>21.483516</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>9873</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.056518</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.154664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054289</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.022384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>81.00</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>9873.0</td>\n",
       "      <td>23.938272</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>6326</td>\n",
       "      <td>0.772210</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.160765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060070</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.039203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>6326.0</td>\n",
       "      <td>28.627907</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>7751</td>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.050187</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.171204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056896</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>7751.0</td>\n",
       "      <td>26.283333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>7189</td>\n",
       "      <td>0.744749</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.177076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055223</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>43.676471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>9006</td>\n",
       "      <td>0.754164</td>\n",
       "      <td>0.059294</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.174106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>16.25</td>\n",
       "      <td>412.5</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>30.870968</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_characters  ratio_alphabetic  ratio_uppercase  ratio_digit  \\\n",
       "0                 9587          0.761135         0.071242     0.013038   \n",
       "1                 9713          0.755379         0.082879     0.016782   \n",
       "2                 9408          0.773278         0.068240     0.018282   \n",
       "3                 7483          0.755579         0.080583     0.013631   \n",
       "4                10457          0.776991         0.058334     0.009754   \n",
       "...                ...               ...              ...          ...   \n",
       "2395              9873          0.771903         0.056518     0.012357   \n",
       "2396              6326          0.772210         0.051533     0.012646   \n",
       "2397              7751          0.758741         0.050187     0.013160   \n",
       "2398              7189          0.744749         0.059814     0.013632   \n",
       "2399              9006          0.754164         0.059294     0.008883   \n",
       "\n",
       "      ratio_whitespace  ratio_tabspace  a_frequency  b_frequency  c_frequency  \\\n",
       "0             0.158652             0.0     0.053927     0.013664     0.024512   \n",
       "1             0.155977             0.0     0.060743     0.013075     0.030989   \n",
       "2             0.144770             0.0     0.060587     0.012117     0.030293   \n",
       "3             0.162903             0.0     0.058533     0.018709     0.023386   \n",
       "4             0.145931             0.0     0.057665     0.013006     0.023047   \n",
       "...                ...             ...          ...          ...          ...   \n",
       "2395          0.154664             0.0     0.054289     0.016915     0.023600   \n",
       "2396          0.160765             0.0     0.060070     0.008694     0.018179   \n",
       "2397          0.171204             0.0     0.056896     0.013676     0.024255   \n",
       "2398          0.177076             0.0     0.055223     0.014188     0.020865   \n",
       "2399          0.174106             0.0     0.062625     0.014657     0.019543   \n",
       "\n",
       "      d_frequency  ...  \\.{3}_frequency  number_lines  number_sentences  \\\n",
       "0        0.021487  ...         0.000730             4                83   \n",
       "1        0.021312  ...         0.000309             2               145   \n",
       "2        0.022215  ...         0.000744             4               121   \n",
       "3        0.020847  ...         0.000000             7                40   \n",
       "4        0.023429  ...         0.000096            12                91   \n",
       "...           ...  ...              ...           ...               ...   \n",
       "2395     0.022384  ...         0.000506             1                81   \n",
       "2396     0.039203  ...         0.000790             2                43   \n",
       "2397     0.023481  ...         0.000645            16                60   \n",
       "2398     0.025595  ...         0.000000             6                34   \n",
       "2399     0.024317  ...         0.000333             7                62   \n",
       "\n",
       "      number_paragraphs  sentences_per_paragraph  word_per_paragraph  \\\n",
       "0                     1                    83.00              1737.0   \n",
       "1                     1                   145.00              1686.0   \n",
       "2                     2                    61.00               753.5   \n",
       "3                     2                    20.50               672.5   \n",
       "4                     1                    91.00              1690.0   \n",
       "...                 ...                      ...                 ...   \n",
       "2395                  1                    81.00              1724.0   \n",
       "2396                  1                    43.00              1057.0   \n",
       "2397                  1                    60.00              1431.0   \n",
       "2398                  1                    34.00              1359.0   \n",
       "2399                  4                    16.25               412.5   \n",
       "\n",
       "      character_per_paragraph  word_per_sentence  \\\n",
       "0                      9587.0          22.650602   \n",
       "1                      9713.0          13.862069   \n",
       "2                      4703.0          14.694215   \n",
       "3                      3740.5          36.525000   \n",
       "4                     10457.0          21.483516   \n",
       "...                       ...                ...   \n",
       "2395                   9873.0          23.938272   \n",
       "2396                   6326.0          28.627907   \n",
       "2397                   7751.0          26.283333   \n",
       "2398                   7189.0          43.676471   \n",
       "2399                   2250.0          30.870968   \n",
       "\n",
       "      ratio_sentencestart_uppercase  gender  \n",
       "0                          0.674699  female  \n",
       "1                          0.517241  female  \n",
       "2                          0.479339    male  \n",
       "3                          0.450000  female  \n",
       "4                          0.560440  female  \n",
       "...                             ...     ...  \n",
       "2395                       0.580247    male  \n",
       "2396                       0.441860  female  \n",
       "2397                       0.650000  female  \n",
       "2398                       0.117647  female  \n",
       "2399                       0.645161    male  \n",
       "\n",
       "[2400 rows x 83 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pan17_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_test.to_csv(r'data\\pan15_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train.to_csv(r'data\\pan15_features_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_test.to_csv(r'data\\pan17_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_train.to_csv(r'data\\pan17_features_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train_tfidf_array = tfidf.fit_transform(data_pan15_training['text'])\n",
    "pan15_test_tfidf_array = tfidf.transform(data_pan15_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_train_tfidf_array = tfidf.fit_transform(data_pan17_train['text'])\n",
    "pan17_test_tfidf_array = tfidf.transform(data_pan17_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train_lsa = lsa.fit_transform(pan15_train_tfidf_array)\n",
    "pan15_test_lsa = lsa.transform(pan15_test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan17_train_lsa = lsa.fit_transform(pan17_train_tfidf_array)\n",
    "pan17_test_lsa = lsa.transform(pan17_test_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "pan15_train_tfidf = pd.DataFrame(pan15_train_tfidf_array.toarray(), columns=feature_names)\n",
    "pan15_test_tfidf = pd.DataFrame(pan15_test_tfidf_array.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan15_train_tfidf.to_csv(r'data\\pan15_tfidf_train.csv', index=False)\n",
    "pan15_test_tfidf.to_csv(r'data\\pan15_tfidf_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14166"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_pan15_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pan15_train_lsa\n",
    "y_train = data_pan15_training['gender']\n",
    "X_test = pan15_test_lsa\n",
    "y_test = data_pan15_test['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pan17_train_lsa\n",
    "y_train = data_pan17_train['gender']\n",
    "X_test = pan17_test_lsa\n",
    "y_test = data_pan17_test['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_pan17_train_features.drop(columns=['gender'])\n",
    "y_train = combined_pan17_train_features['gender']\n",
    "X_test = combined_pan17_test_features.drop(columns=['gender'])\n",
    "y_test = combined_pan17_test_features['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933333333333334"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), sublinear_tf=True, min_df=2)\n",
    "#char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), min_df=2)\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), sublinear_tf=True, min_df=2)\n",
    "#word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('char', char_vectorizer),\n",
    "    ('word', word_vectorizer)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('svm', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_pan17_train['text']\n",
    "y_train = combined_pan17_train['gender']\n",
    "X_test = combined_pan17_test['text']\n",
    "y_test = combined_pan17_test['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;char&#x27;,\n",
       "                                                 TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                 min_df=2,\n",
       "                                                                 ngram_range=(3,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True)),\n",
       "                                                (&#x27;word&#x27;,\n",
       "                                                 TfidfVectorizer(min_df=2,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;svm&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;char&#x27;,\n",
       "                                                 TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                 min_df=2,\n",
       "                                                                 ngram_range=(3,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True)),\n",
       "                                                (&#x27;word&#x27;,\n",
       "                                                 TfidfVectorizer(min_df=2,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;svm&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;char&#x27;,\n",
       "                                TfidfVectorizer(analyzer=&#x27;char&#x27;, min_df=2,\n",
       "                                                ngram_range=(3, 5),\n",
       "                                                sublinear_tf=True)),\n",
       "                               (&#x27;word&#x27;,\n",
       "                                TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                                sublinear_tf=True))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>char</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, min_df=2, ngram_range=(3, 5),\n",
       "                sublinear_tf=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>word</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(min_df=2, ngram_range=(1, 2), sublinear_tf=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('char',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 min_df=2,\n",
       "                                                                 ngram_range=(3,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True)),\n",
       "                                                ('word',\n",
       "                                                 TfidfVectorizer(min_df=2,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('svm', LinearSVC())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195833333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_pan17_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_pan17_train \u001b[38;5;241m=\u001b[39m \u001b[43mdata_pan17_train\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      5\u001b[0m combined_pan17_test \u001b[38;5;241m=\u001b[39m data_pan17_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_pan17_train' is not defined"
     ]
    }
   ],
   "source": [
    "combined_pan17_train = data_pan17_train.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first'\n",
    "}).reset_index()\n",
    "combined_pan17_test = data_pan17_test.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100c885443c4d2a32075e10cbca9a27e</td>\n",
       "      <td>Less than 2 weeks until Valentine's Day https:...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017647e21e7e73d900e1dfacbf95a0f</td>\n",
       "      <td>@drakefenton FWIW, you were wrong four  hours ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023e1e534622e28d29dfdc0ee45cdac</td>\n",
       "      <td>I'm marching in CBR. Your big city ain't going...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10283d7f37d33b063e3734b740f5229d</td>\n",
       "      <td>More pics for BTS' comeback Cr. Naver https://...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1069f66c9d5862f860277d32780ac459</td>\n",
       "      <td>@griffski Eh? Great message to be sending out....</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>ffa1dd4f39b1e32dcd1274327af39eac</td>\n",
       "      <td>@aliceisms fake news By this point, surely my ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>ffd6c6cfe9c484d3538fb9d9a628af74</td>\n",
       "      <td>@timkaine now that he is Sec of state how can ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>ffd9b325eddf0c9374ad5eabeca6860a</td>\n",
       "      <td>.@acquia_support Is dev desktop supported on M...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>ffe4df0924e74cdc1d0ec6b980529ae7</td>\n",
       "      <td>anyway i'm super gay and @downtongaby is super...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>fff5a17288a8ab173e493c90bf4b39a4</td>\n",
       "      <td>@woahrebecca @h0ltzmann_ tomorrow I shall slow...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                author  \\\n",
       "0     100c885443c4d2a32075e10cbca9a27e   \n",
       "1     1017647e21e7e73d900e1dfacbf95a0f   \n",
       "2     1023e1e534622e28d29dfdc0ee45cdac   \n",
       "3     10283d7f37d33b063e3734b740f5229d   \n",
       "4     1069f66c9d5862f860277d32780ac459   \n",
       "...                                ...   \n",
       "2395  ffa1dd4f39b1e32dcd1274327af39eac   \n",
       "2396  ffd6c6cfe9c484d3538fb9d9a628af74   \n",
       "2397  ffd9b325eddf0c9374ad5eabeca6860a   \n",
       "2398  ffe4df0924e74cdc1d0ec6b980529ae7   \n",
       "2399  fff5a17288a8ab173e493c90bf4b39a4   \n",
       "\n",
       "                                                   text  gender  \n",
       "0     Less than 2 weeks until Valentine's Day https:...  female  \n",
       "1     @drakefenton FWIW, you were wrong four  hours ...  female  \n",
       "2     I'm marching in CBR. Your big city ain't going...    male  \n",
       "3     More pics for BTS' comeback Cr. Naver https://...  female  \n",
       "4     @griffski Eh? Great message to be sending out....  female  \n",
       "...                                                 ...     ...  \n",
       "2395  @aliceisms fake news By this point, surely my ...    male  \n",
       "2396  @timkaine now that he is Sec of state how can ...  female  \n",
       "2397  .@acquia_support Is dev desktop supported on M...  female  \n",
       "2398  anyway i'm super gay and @downtongaby is super...  female  \n",
       "2399  @woahrebecca @h0ltzmann_ tomorrow I shall slow...    male  \n",
       "\n",
       "[2400 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pan17_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
