{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering research question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_train = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_training.csv')\n",
    "data_pan15_test = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train = data_pan15_train.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()\n",
    "combined_pan15_test = data_pan15_test.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt1.csv')\n",
    "df_gemini = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini1.csv')\n",
    "df_llama = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt2_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_male.csv')\n",
    "df_gpt2_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_female.csv')\n",
    "df_gpt2_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_18_24.csv')\n",
    "df_gpt2_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_25_34.csv')\n",
    "df_gpt2_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_35_49.csv')\n",
    "df_gpt2_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt2_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gemini2_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_male.csv')\n",
    "df_gemini2_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_female.csv')\n",
    "df_gemini2_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_18_24.csv')\n",
    "df_gemini2_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_25_34.csv')\n",
    "df_gemini2_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_35_49.csv')\n",
    "df_gemini2_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini2_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama2_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_male.csv')\n",
    "df_llama2_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_female.csv')\n",
    "df_llama2_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_18_24.csv')\n",
    "df_llama2_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_25_34.csv')\n",
    "df_llama2_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_35_49.csv')\n",
    "df_llama2_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama2_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt3_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_male.csv')\n",
    "df_gpt3_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_female.csv')\n",
    "df_gpt3_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_18_24.csv')\n",
    "df_gpt3_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_25_34.csv')\n",
    "df_gpt3_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_35_49.csv')\n",
    "df_gpt3_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt3_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gemini3_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_male.csv')\n",
    "df_gemini3_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_female.csv')\n",
    "df_gemini3_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_18_24.csv')\n",
    "df_gemini3_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_25_34.csv')\n",
    "df_gemini3_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_35_49.csv')\n",
    "df_gemini3_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini3_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama3_male = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_male.csv')\n",
    "df_llama3_female = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_female.csv')\n",
    "df_llama3_18_24 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_18_24.csv')\n",
    "df_llama3_25_34 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_25_34.csv')\n",
    "df_llama3_35_49 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_35_49.csv')\n",
    "df_llama3_50 = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\llama3_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Character-based features\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def alphabetic_ratio(text):\n",
    "    alphabetic = sum(c.isalpha() for c in text)\n",
    "    return alphabetic/len(text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    upper = sum(c.isupper() for c in text)\n",
    "    return upper/len(text)\n",
    "\n",
    "def digit_ratio(text):\n",
    "    digit = sum(c.isdigit() for c in text)\n",
    "    return digit/len(text)\n",
    "\n",
    "def whitespace_ratio(text):\n",
    "    whitespace = sum(c.isspace() for c in text)\n",
    "    return whitespace/len(text)\n",
    "\n",
    "def tab_ratio(text):\n",
    "    tabs = text.count('\\t')\n",
    "    return tabs/len(text)\n",
    "\n",
    "def letter_ratio(text, letter):\n",
    "    text = text.lower()\n",
    "    letter_count = text.count(letter)\n",
    "    return letter_count/len(text)\n",
    "\n",
    "def specialcharacter_ratio(text, character):\n",
    "    spec_count = text.count(character)\n",
    "    return spec_count/len(text)\n",
    "\n",
    "# Word-based features\n",
    "def number_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n",
    "def word_length(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length/num_words\n",
    "\n",
    "def vocabulary_richness(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_uniq_words = len(set(words))\n",
    "    return num_uniq_words/num_words\n",
    "\n",
    "def long_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    long_words_list = [word for word in words if len(word) > 6]\n",
    "    return len(long_words_list)/len(words)\n",
    "\n",
    "def short_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words_list = [word for word in words if 1 <= len(word) <= 3]\n",
    "    return len(short_words_list)/len(words)\n",
    "\n",
    "def legomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    return len(legomena)/len(words)\n",
    "\n",
    "def dislegomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    return len(dislegomena)/len(words)\n",
    "\n",
    "def yules_k(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    Vi = FreqDist(freq.values())\n",
    "    K = 10**4 * ((-N + sum(i**2 * Vi[i] for i in Vi))/N**2)\n",
    "    return K\n",
    "\n",
    "def simpson_d(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    if N < 2:\n",
    "        return 0\n",
    "    D = sum(fr * (fr - 1) / (N * (N - 1)) for fr in freq.values())\n",
    "    return D\n",
    "\n",
    "def sichel_s(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    S = len(dislegomena)/len(freq.values())\n",
    "    return S\n",
    "\n",
    "def honores_r(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if not words:\n",
    "        return 0\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    V = len(freq.values())\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    unique_count_ratio = len(legomena) / V if V > 0 else 0\n",
    "    if unique_count_ratio == 1 or N == 0:\n",
    "        return 0\n",
    "    R = (100*np.log(N)/(1-(len(legomena)/V)))\n",
    "    return R\n",
    "\n",
    "def entropy(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    E = -sum((fr / N) * np.log(fr/N) for fr in freq.values())\n",
    "    return E\n",
    "\n",
    "# Syntatic features\n",
    "def punctuations_ratio(text, punctuation):\n",
    "    punctuation_list = re.findall(punctuation, text)\n",
    "    return len(punctuation_list)/len(text)\n",
    "\n",
    "# Structural features\n",
    "def lines(text):\n",
    "    return len(text.split('\\n'))\n",
    "\n",
    "def sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "def paragraphs(text):\n",
    "    return len([par for par in text.split('\\n\\n') if par.strip()])\n",
    "\n",
    "def sentence_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(sent_tokenize(par)) for par in pars])\n",
    "\n",
    "def words_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(re.findall(r'\\b\\w+\\b', par)) for par in pars])\n",
    "\n",
    "def chars_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(par) for par in pars])\n",
    "\n",
    "def words_sentences(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return statistics.mean([len(word_tokenize(sentence)) for sentence in sents])\n",
    "\n",
    "def uppercase_start(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return (sum(1 for sentence in sents if sentence[0].isupper()) / len(sents))\n",
    "\n",
    "def extract_features(dataframe, text_column):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Character-based features\n",
    "    features['total_characters'] = dataframe[text_column].apply(character_count)\n",
    "    features['ratio_alphabetic'] = dataframe[text_column].apply(alphabetic_ratio)\n",
    "    features['ratio_uppercase'] = dataframe[text_column].apply(uppercase_ratio)\n",
    "    features['ratio_digit'] = dataframe[text_column].apply(digit_ratio)\n",
    "    features['ratio_whitespace'] = dataframe[text_column].apply(whitespace_ratio)\n",
    "    features['ratio_tabspace'] = dataframe[text_column].apply(tab_ratio)\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for letter in letters:\n",
    "        features[letter+'_frequency'] = dataframe[text_column].apply(letter_ratio, args=(letter,))\n",
    "    special_characters = ['~', '@', '#', '$', '%', '^', '&', '*', '-', '_', '=', '+', '>', '<', '[', ']', '{', '}', '/', '\\\\', '|']\n",
    "    for character in special_characters:\n",
    "        features[character+'_frequency'] = dataframe[text_column].apply(specialcharacter_ratio, args=(character,))\n",
    "    \n",
    "    # Word-based features\n",
    "    features['total_words'] = dataframe[text_column].apply(number_words)\n",
    "    features['word_length'] = dataframe[text_column].apply(word_length)\n",
    "    features['vocabulary_richness'] = dataframe[text_column].apply(vocabulary_richness)\n",
    "    features['long_words'] = dataframe[text_column].apply(long_words)\n",
    "    features['short_words'] = dataframe[text_column].apply(short_words)\n",
    "    features['hapax_legomena'] = dataframe[text_column].apply(legomena)\n",
    "    features['hapax_dislegomena'] = dataframe[text_column].apply(dislegomena)\n",
    "    features['yules_k'] = dataframe[text_column].apply(yules_k)\n",
    "    features['simpson_d'] = dataframe[text_column].apply(simpson_d)\n",
    "    features['sichel_s'] = dataframe[text_column].apply(sichel_s)\n",
    "    #features['honore_r'] = dataframe[text_column].apply(honores_r)\n",
    "    features['entropy'] =  dataframe[text_column].apply(entropy)\n",
    "    # Brunet W?\n",
    "    # word length frequency distribution\n",
    "\n",
    "    \n",
    "    # Syntactic features\n",
    "    punctuations = [r\"’\", r\",\", r\"\\.\", r\":\", r\";\", r\"\\?\", r\"\\?{2,}\", r\"!\", r\"!{2,}\", r\"\\.{3}\"]\n",
    "    for punctuation in punctuations:\n",
    "        features[punctuation+\"_frequency\"] = dataframe[text_column].apply(punctuations_ratio, args=(punctuation,))\n",
    "\n",
    "    # Structural features\n",
    "    features['number_lines'] = dataframe[text_column].apply(lines)\n",
    "    features['number_sentences'] = dataframe[text_column].apply(sentences)\n",
    "    features['number_paragraphs'] = dataframe[text_column].apply(paragraphs)\n",
    "    features['sentences_per_paragraph'] = dataframe[text_column].apply(sentence_paragraph)\n",
    "    features['word_per_paragraph'] = dataframe[text_column].apply(words_paragraph)\n",
    "    features['character_per_paragraph'] = dataframe[text_column].apply(chars_paragraph)\n",
    "    features['word_per_sentence'] = dataframe[text_column].apply(words_sentences)\n",
    "    features['ratio_sentencestart_uppercase'] = dataframe[text_column].apply(uppercase_start)\n",
    "    #features['gender'] = dataframe['gender']\n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train_features = extract_features(combined_pan15_train, 'text')\n",
    "combined_pan15_test_features = extract_features(combined_pan15_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "combined_pan15_train_features_scaled = pd.DataFrame(scaler.fit_transform(combined_pan15_train_features), columns=combined_pan15_train_features.columns)\n",
    "combined_pan15_test_features_scaled = pd.DataFrame(scaler.transform(combined_pan15_test_features), columns=combined_pan15_test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_pan15_train_features_scaled\n",
    "X_test = combined_pan15_test_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = combined_pan15_train['gender']\n",
    "y_test = combined_pan15_test['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=0.01, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.01, max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=0.01, max_iter=10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=10000, C= 0.01, class_weight= None, loss= 'squared_hinge', tol= 0.0001)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7535211267605634"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), sublinear_tf=True, min_df=2)\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), sublinear_tf=True, min_df=2)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('char', char_vectorizer),\n",
    "    ('word', word_vectorizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features_train = combined_features.fit_transform(combined_pan15_train['text'])\n",
    "tfidf_features_test =  combined_features.transform(combined_pan15_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([tfidf_features_train, csr_matrix(combined_pan15_train_features_scaled)])\n",
    "X_test = hstack([tfidf_features_test, csr_matrix(combined_pan15_test_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_label_encoder(labels, mapping):\n",
    "#     return np.array([mapping[label] for label in labels])\n",
    "\n",
    "# label_mapping = {'F': 1, 'M': 0}\n",
    "# y_train = custom_label_encoder(y_train, label_mapping)\n",
    "# y_test = custom_label_encoder(y_test, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = label_encoder.fit_transform(y_train)\n",
    "# y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classes:\", label_encoder.classes_)\n",
    "# print(\"Encoded values:\", label_encoder.transform(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n",
      "Precision: 0.765\n",
      "Recall: 0.732\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=10000, C= 0.01, class_weight= None, loss= 'squared_hinge', tol= 0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred, pos_label='M'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred, pos_label='M'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.754\n",
      "Precision: 0.79\n",
      "Recall: 0.69\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_lr), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_lr, pos_label='M'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred_lr, pos_label='M'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.711\n",
      "Precision: 0.742\n",
      "Recall: 0.648\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=1700)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_rf), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_rf, pos_label='M'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred_rf, pos_label='M'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_score_svm = model.decision_function(X_test)\n",
    "# y_score_lr = model_lr.predict_proba(X_test)[:, 1]\n",
    "# y_score_rf = model_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n",
    "# roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "# fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_score_lr)\n",
    "# roc_auc_logistic = auc(fpr_logistic, tpr_logistic)\n",
    "\n",
    "# fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
    "# roc_auc_rf = auc(fpr_rf, tpr_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "\n",
    "# plt.plot(fpr_svm, tpr_svm, color='blue', lw=2, label='Linear SVM (AUC = %0.2f)' % roc_auc_svm)\n",
    "# plt.plot(fpr_logistic, tpr_logistic, color='green', lw=2, label='Logistic Regression (AUC = %0.2f)' % roc_auc_logistic)\n",
    "# plt.plot(fpr_rf, tpr_rf, color='red', lw=2, label='Random Forest (AUC = %0.2f)' % roc_auc_rf)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "# #plt.savefig(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\graphs/roc_curve_gender1.png')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_age = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_age = combined_pan15_train['age']\n",
    "y_test_age = combined_pan15_test['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\ny_train_age = label_encoder_age.fit_transform(y_train_age)\\ny_test_age = label_encoder_age.transform(y_test_age)\\nclasses = label_encoder_age.classes_\\nn_classes = len(classes)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "y_train_age = label_encoder_age.fit_transform(y_train_age)\n",
    "y_test_age = label_encoder_age.transform(y_test_age)\n",
    "classes = label_encoder_age.classes_\n",
    "n_classes = len(classes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclasses = np.unique(y_train_age)\\ny_train_age = label_binarize(y_train_age, classes=classes)\\ny_test_age = label_binarize(y_test_age, classes=classes)\\nn_classes = y_train_age.shape[1]\\ny_train_age_single = np.argmax(y_train_age, axis=1)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classes = np.unique(y_train_age)\n",
    "y_train_age = label_binarize(y_train_age, classes=classes)\n",
    "y_test_age = label_binarize(y_test_age, classes=classes)\n",
    "n_classes = y_train_age.shape[1]\n",
    "y_train_age_single = np.argmax(y_train_age, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.697\n",
      "Precision: 0.695\n",
      "Recall: 0.697\n"
     ]
    }
   ],
   "source": [
    "model_age = LinearSVC(max_iter=10000, C= 0.01, class_weight= None, loss= 'squared_hinge', tol= 0.0001)\n",
    "model_age.fit(X_train, y_train_age)\n",
    "y_pred_age = model_age.predict(X_test)\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_age, y_pred_age), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test_age, y_pred_age, average='weighted'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test_age, y_pred_age, average='weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.655\n",
      "Precision: 0.677\n",
      "Recall: 0.655\n"
     ]
    }
   ],
   "source": [
    "model_lr_age = LogisticRegression()\n",
    "model_lr_age.fit(X_train, y_train_age)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr_age = model_lr_age.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_age, y_pred_lr_age), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test_age, y_pred_lr_age, average='weighted'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test_age, y_pred_lr_age, average='weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.683\n",
      "Precision: 0.686\n",
      "Recall: 0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_rf_age = RandomForestClassifier(random_state=7390)\n",
    "model_rf_age.fit(X_train, y_train_age)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_age = model_rf_age.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_age, y_pred_rf_age), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test_age, y_pred_rf_age, average='weighted'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test_age, y_pred_rf_age, average='weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_svm_age = model_age.decision_function(X_test)\n",
    "y_score_lr_age = model_lr_age.predict_proba(X_test)\n",
    "y_score_rf_age = model_rf_age.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "# for i in range(n_classes):\n",
    "#     # Binary representation for the current class\n",
    "#     y_test_binary = np.where(y_test_age == i, 1, 0)\n",
    "    \n",
    "#     fpr[f'svm_{i}'], tpr[f'svm_{i}'], _ = roc_curve(y_test_binary, y_score_svm_age[:, i] if y_score_svm_age.ndim > 1 else y_score_svm_age)\n",
    "#     roc_auc[f'svm_{i}'] = auc(fpr[f'svm_{i}'], tpr[f'svm_{i}'])\n",
    "\n",
    "#     fpr[f'logistic_{i}'], tpr[f'logistic_{i}'], _ = roc_curve(y_test_binary, y_score_lr_age[:, i])\n",
    "#     roc_auc[f'logistic_{i}'] = auc(fpr[f'logistic_{i}'], tpr[f'logistic_{i}'])\n",
    "\n",
    "#     fpr[f'rf_{i}'], tpr[f'rf_{i}'], _ = roc_curve(y_test_binary, y_score_rf_age[:, i])\n",
    "#     roc_auc[f'rf_{i}'] = auc(fpr[f'rf_{i}'], tpr[f'rf_{i}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = cycle(['blue', 'green', 'red', 'cyan'])\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(fpr[f'svm_{i}'], tpr[f'svm_{i}'], color=color, lw=2, linestyle='--', label=f'SVM class {classes[i]} (AUC = {roc_auc[f\"svm_{i}\"]:.2f})')\n",
    "#     plt.plot(fpr[f'logistic_{i}'], tpr[f'logistic_{i}'], color=color, lw=2, linestyle='-', label=f'Logistic class {classes[i]} (AUC = {roc_auc[f\"logistic_{i}\"]:.2f})')\n",
    "#     plt.plot(fpr[f'rf_{i}'], tpr[f'rf_{i}'], color=color, lw=2, linestyle=':', label=f'Random Forest class {classes[i]} (AUC = {roc_auc[f\"rf_{i}\"]:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'M': 68, 'F': 74})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting LLM data RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features = extract_features(df_gpt, 'text')\n",
    "gemini_features = extract_features(df_gemini, 'text')\n",
    "llama_features = extract_features(df_llama, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features_scaled = pd.DataFrame(scaler.transform(gpt_features), columns=gpt_features.columns)\n",
    "gemini_features_scaled = pd.DataFrame(scaler.transform(gemini_features), columns=gemini_features.columns)\n",
    "llama_features_scaled = pd.DataFrame(scaler.transform(llama_features), columns=llama_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features_tfidf = combined_features.transform(df_gpt['text'])\n",
    "gpt_features_combined = hstack([gpt_features_tfidf, csr_matrix(gpt_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_features_tfidf = combined_features.transform(df_gemini['text'])\n",
    "gemini_features_combined = hstack([gemini_features_tfidf, csr_matrix(gemini_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_features_tfidf = combined_features.transform(df_llama['text'])\n",
    "llama_features_combined = hstack([llama_features_tfidf, csr_matrix(llama_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio GPT: 0.436\n",
      "Counter({'F': 141, 'M': 109})\n"
     ]
    }
   ],
   "source": [
    "gpt_pred = model.predict(gpt_features_combined)\n",
    "print(\"Male-ratio GPT: \" + str(Counter(gpt_pred)[\"M\"] / len(gpt_pred)))\n",
    "print(Counter(gpt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio Gemini: 0.9562043795620438\n",
      "Counter({'M': 131, 'F': 6})\n"
     ]
    }
   ],
   "source": [
    "gemini_pred = model.predict(gemini_features_combined)\n",
    "print(\"Male-ratio Gemini: \" + str(Counter(gemini_pred)[\"M\"] / len(gemini_pred)))\n",
    "print(Counter(gemini_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio llama: 0.6825396825396826\n",
      "Counter({'M': 129, 'F': 60})\n"
     ]
    }
   ],
   "source": [
    "llama_pred = model.predict(llama_features_combined)\n",
    "print(\"Male-ratio llama: \" + str(Counter(llama_pred)[\"M\"] / len(llama_pred)))\n",
    "print(Counter(llama_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.DataFrame({\n",
    "    \"GPT\" : pd.Series(gpt_pred).value_counts(),\n",
    "    \"Gemini\" : pd.Series(gemini_pred).value_counts(),\n",
    "    \"Llama\" : pd.Series(llama_pred).value_counts()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT</th>\n",
       "      <th>Gemini</th>\n",
       "      <th>Llama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>109</td>\n",
       "      <td>131</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GPT  Gemini  Llama\n",
       "F  141       6     60\n",
       "M  109     131    129"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(contingency_table.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Square Test Results:\n",
      "Chi-Square Statistic: 106.17356605188847\n",
      "P-Value: 8.804466996342262e-24\n",
      "Degrees of Freedom: 2\n",
      "Expected Frequencies:\n",
      "                F           M\n",
      "GPT     89.843750  160.156250\n",
      "Gemini  49.234375   87.765625\n",
      "Llama   67.921875  121.078125\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChi-Square Test Results:\")\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.columns, columns=contingency_table.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 4.096\n",
      "P-value: 0.042984795070858665\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(gpt_pred)/2, len(gpt_pred)/2]\n",
    "chi2_stat, p_val = chisquare(pd.Series(gpt_pred).value_counts(), expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 114.05109489051095\n",
      "P-value: 1.2699362592974781e-26\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(gemini_pred)/2, len(gemini_pred)/2]\n",
    "chi2_stat, p_val = chisquare(pd.Series(gemini_pred).value_counts(), expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 25.19047619047619\n",
      "P-value: 5.193804760844568e-07\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(llama_pred)/2, len(llama_pred)/2]\n",
    "chi2_stat, p_val = chisquare(pd.Series(llama_pred).value_counts(), expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'25-34': 250})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_pred_age = model_age.predict(gpt_features_combined)\n",
    "Counter(gpt_pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'25-34': 115, '35-49': 22})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_pred_age = model_age.predict(gemini_features_combined)\n",
    "Counter(gemini_pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'18-24': 21, '25-34': 147, '35-49': 21})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_pred_age = model_age.predict(llama_features_combined)\n",
    "Counter(llama_pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_age = pd.DataFrame({\n",
    "    \"GPT\" : pd.Series(gpt_pred_age).value_counts(),\n",
    "    \"Gemini\" : pd.Series(gemini_pred_age).value_counts(),\n",
    "    \"Llama\" : pd.Series(llama_pred_age).value_counts()\n",
    "}).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Square Test Results:\n",
      "Chi-Square Statistic: 85.05398064844678\n",
      "P-Value: 1.4774793140887388e-17\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies:\n",
      "            0           1           2\n",
      "0    9.114583    4.994792    6.890625\n",
      "1  222.222222  121.777778  168.000000\n",
      "2   18.663194   10.227431   14.109375\n"
     ]
    }
   ],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(contingency_table_age)\n",
    "print(\"\\nChi-Square Test Results:\")\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(pd.DataFrame(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_age.loc['50+'] = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT</th>\n",
       "      <th>Gemini</th>\n",
       "      <th>Llama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25-34</th>\n",
       "      <td>250</td>\n",
       "      <td>115</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35-49</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50+</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GPT  Gemini  Llama\n",
       "18-24    0       0     21\n",
       "25-34  250     115    147\n",
       "35-49    0      22     21\n",
       "50+      0       0      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-34    250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gpt_pred_age).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 376.86492314636047\n",
      "P-value: 2.269877829742244e-81\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(gpt_pred_age)*0.38690, len(gpt_pred_age)*0.39881, len(gpt_pred_age)*0.14286, len(gpt_pred_age)*0.07143]\n",
    "chi2_stat, p_val = chisquare(contingency_table_age['GPT'], expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 129.78165456786598\n",
      "P-value: 6.0273582001307705e-28\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(gemini_pred_age)*0.38690, len(gemini_pred_age)*0.39881, len(gemini_pred_age)*0.14286, len(gemini_pred_age)*0.07143]\n",
    "chi2_stat, p_val = chisquare(contingency_table_age['Gemini'], expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 120.05007498200354\n",
      "P-value: 7.52752452704496e-26\n"
     ]
    }
   ],
   "source": [
    "expected_frequencies = [len(llama_pred_age)*0.38690, len(llama_pred_age)*0.39881, len(llama_pred_age)*0.14286, len(llama_pred_age)*0.07143]\n",
    "chi2_stat, p_val = chisquare(contingency_table_age['Llama'], expected_frequencies)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_male_features = extract_features(df_gpt2_male, 'text')\n",
    "gpt2_female_features = extract_features(df_gpt2_female, 'text')\n",
    "gpt2_18_24_features = extract_features(df_gpt2_18_24, 'text')\n",
    "gpt2_25_34_features = extract_features(df_gpt2_25_34, 'text')\n",
    "gpt2_35_49_features = extract_features(df_gpt2_35_49, 'text')\n",
    "gpt2_50_features = extract_features(df_gpt2_50, 'text')\n",
    "\n",
    "gpt2_male_features_scaled = pd.DataFrame(scaler.transform(gpt2_male_features), columns=gpt2_male_features.columns)\n",
    "gpt2_female_features_scaled = pd.DataFrame(scaler.transform(gpt2_female_features), columns=gpt2_female_features.columns)\n",
    "gpt2_18_24_features_scaled = pd.DataFrame(scaler.transform(gpt2_18_24_features), columns=gpt2_18_24_features.columns)\n",
    "gpt2_25_34_features_scaled = pd.DataFrame(scaler.transform(gpt2_25_34_features), columns=gpt2_25_34_features.columns)\n",
    "gpt2_35_49_features_scaled = pd.DataFrame(scaler.transform(gpt2_35_49_features), columns=gpt2_35_49_features.columns)\n",
    "gpt2_50_features_scaled = pd.DataFrame(scaler.transform(gpt2_50_features), columns=gpt2_50_features.columns)\n",
    "\n",
    "gpt2_male_features_tfidf = combined_features.transform(df_gpt2_male['text'])\n",
    "gpt2_female_features_tfidf = combined_features.transform(df_gpt2_female['text'])\n",
    "gpt2_18_24_features_tfidf = combined_features.transform(df_gpt2_18_24['text'])\n",
    "gpt2_25_34_features_tfidf = combined_features.transform(df_gpt2_25_34['text'])\n",
    "gpt2_35_49_features_tfidf = combined_features.transform(df_gpt2_35_49['text'])\n",
    "gpt2_50_features_tfidf = combined_features.transform(df_gpt2_50['text'])\n",
    "\n",
    "gpt2_male_features_combined = hstack([gpt2_male_features_tfidf, csr_matrix(gpt2_male_features_scaled)])\n",
    "gpt2_female_features_combined = hstack([gpt2_female_features_tfidf, csr_matrix(gpt2_female_features_scaled)])\n",
    "gpt2_18_24_features_combined = hstack([gpt2_18_24_features_tfidf, csr_matrix(gpt2_18_24_features_scaled)])\n",
    "gpt2_25_34_features_combined = hstack([gpt2_25_34_features_tfidf, csr_matrix(gpt2_25_34_features_scaled)])\n",
    "gpt2_35_49_features_combined = hstack([gpt2_35_49_features_tfidf, csr_matrix(gpt2_35_49_features_scaled)])\n",
    "gpt2_50_features_combined = hstack([gpt2_50_features_tfidf, csr_matrix(gpt2_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini2_male_features = extract_features(df_gemini2_male, 'text')\n",
    "gemini2_female_features = extract_features(df_gemini2_female, 'text')\n",
    "gemini2_18_24_features = extract_features(df_gemini2_18_24, 'text')\n",
    "gemini2_25_34_features = extract_features(df_gemini2_25_34, 'text')\n",
    "gemini2_35_49_features = extract_features(df_gemini2_35_49, 'text')\n",
    "gemini2_50_features = extract_features(df_gemini2_50, 'text')\n",
    "\n",
    "gemini2_male_features_scaled = pd.DataFrame(scaler.transform(gemini2_male_features), columns=gemini2_male_features.columns)\n",
    "gemini2_female_features_scaled = pd.DataFrame(scaler.transform(gemini2_female_features), columns=gemini2_female_features.columns)\n",
    "gemini2_18_24_features_scaled = pd.DataFrame(scaler.transform(gemini2_18_24_features), columns=gemini2_18_24_features.columns)\n",
    "gemini2_25_34_features_scaled = pd.DataFrame(scaler.transform(gemini2_25_34_features), columns=gemini2_25_34_features.columns)\n",
    "gemini2_35_49_features_scaled = pd.DataFrame(scaler.transform(gemini2_35_49_features), columns=gemini2_35_49_features.columns)\n",
    "gemini2_50_features_scaled = pd.DataFrame(scaler.transform(gemini2_50_features), columns=gemini2_50_features.columns)\n",
    "\n",
    "gemini2_male_features_tfidf = combined_features.transform(df_gemini2_male['text'])\n",
    "gemini2_female_features_tfidf = combined_features.transform(df_gemini2_female['text'])\n",
    "gemini2_18_24_features_tfidf = combined_features.transform(df_gemini2_18_24['text'])\n",
    "gemini2_25_34_features_tfidf = combined_features.transform(df_gemini2_25_34['text'])\n",
    "gemini2_35_49_features_tfidf = combined_features.transform(df_gemini2_35_49['text'])\n",
    "gemini2_50_features_tfidf = combined_features.transform(df_gemini2_50['text'])\n",
    "\n",
    "gemini2_male_features_combined = hstack([gemini2_male_features_tfidf, csr_matrix(gemini2_male_features_scaled)])\n",
    "gemini2_female_features_combined = hstack([gemini2_female_features_tfidf, csr_matrix(gemini2_female_features_scaled)])\n",
    "gemini2_18_24_features_combined = hstack([gemini2_18_24_features_tfidf, csr_matrix(gemini2_18_24_features_scaled)])\n",
    "gemini2_25_34_features_combined = hstack([gemini2_25_34_features_tfidf, csr_matrix(gemini2_25_34_features_scaled)])\n",
    "gemini2_35_49_features_combined = hstack([gemini2_35_49_features_tfidf, csr_matrix(gemini2_35_49_features_scaled)])\n",
    "gemini2_50_features_combined = hstack([gemini2_50_features_tfidf, csr_matrix(gemini2_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_male_features = extract_features(df_llama2_male, 'text')\n",
    "llama2_female_features = extract_features(df_llama2_female, 'text')\n",
    "llama2_18_24_features = extract_features(df_llama2_18_24, 'text')\n",
    "llama2_25_34_features = extract_features(df_llama2_25_34, 'text')\n",
    "llama2_35_49_features = extract_features(df_llama2_35_49, 'text')\n",
    "llama2_50_features = extract_features(df_llama2_50, 'text')\n",
    "\n",
    "llama2_male_features_scaled = pd.DataFrame(scaler.transform(llama2_male_features), columns=llama2_male_features.columns)\n",
    "llama2_female_features_scaled = pd.DataFrame(scaler.transform(llama2_female_features), columns=llama2_female_features.columns)\n",
    "llama2_18_24_features_scaled = pd.DataFrame(scaler.transform(llama2_18_24_features), columns=llama2_18_24_features.columns)\n",
    "llama2_25_34_features_scaled = pd.DataFrame(scaler.transform(llama2_25_34_features), columns=llama2_25_34_features.columns)\n",
    "llama2_35_49_features_scaled = pd.DataFrame(scaler.transform(llama2_35_49_features), columns=llama2_35_49_features.columns)\n",
    "llama2_50_features_scaled = pd.DataFrame(scaler.transform(llama2_50_features), columns=llama2_50_features.columns)\n",
    "\n",
    "llama2_male_features_tfidf = combined_features.transform(df_llama2_male['text'])\n",
    "llama2_female_features_tfidf = combined_features.transform(df_llama2_female['text'])\n",
    "llama2_18_24_features_tfidf = combined_features.transform(df_llama2_18_24['text'])\n",
    "llama2_25_34_features_tfidf = combined_features.transform(df_llama2_25_34['text'])\n",
    "llama2_35_49_features_tfidf = combined_features.transform(df_llama2_35_49['text'])\n",
    "llama2_50_features_tfidf = combined_features.transform(df_llama2_50['text'])\n",
    "\n",
    "llama2_male_features_combined = hstack([llama2_male_features_tfidf, csr_matrix(llama2_male_features_scaled)])\n",
    "llama2_female_features_combined = hstack([llama2_female_features_tfidf, csr_matrix(llama2_female_features_scaled)])\n",
    "llama2_18_24_features_combined = hstack([llama2_18_24_features_tfidf, csr_matrix(llama2_18_24_features_scaled)])\n",
    "llama2_25_34_features_combined = hstack([llama2_25_34_features_tfidf, csr_matrix(llama2_25_34_features_scaled)])\n",
    "llama2_35_49_features_combined = hstack([llama2_35_49_features_tfidf, csr_matrix(llama2_35_49_features_scaled)])\n",
    "llama2_50_features_combined = hstack([llama2_50_features_tfidf, csr_matrix(llama2_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio gpt2_male: 1.0\n",
      "Distribution gpt2_male: Counter({'M': 53})\n",
      "\n",
      "Male-ratio gpt2_female: 1.0\n",
      "Distribution gpt2_female: Counter({'M': 52})\n",
      "\n",
      "Distribution gpt2_18_24: Counter({'35-49': 60})\n",
      "\n",
      "Distribution gpt2_25_34: Counter({'25-34': 53})\n",
      "\n",
      "Distribution gpt2_35_49: Counter({'25-34': 54})\n",
      "\n",
      "Distribution gpt2_50: Counter({'25-34': 46, '35-49': 11})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2_male_pred = pd.Series(model.predict(gpt2_male_features_combined)).sample(n=53, random_state=7234)\n",
    "gpt2_female_pred = pd.Series(model.predict(gpt2_female_features_combined)).sample(n=52, random_state=8725)\n",
    "gpt2_18_24_pred = model_age.predict(gpt2_18_24_features_combined)\n",
    "gpt2_25_34_pred = model_age.predict(gpt2_25_34_features_combined)\n",
    "gpt2_35_49_pred = model_age.predict(gpt2_35_49_features_combined)\n",
    "gpt2_50_pred = model_age.predict(gpt2_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio gpt2_male: \" + str(Counter(gpt2_male_pred)[\"M\"] / len(gpt2_male_pred)))\n",
    "print(\"Distribution gpt2_male: \" + str(Counter(gpt2_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio gpt2_female: \" + str(Counter(gpt2_female_pred)[\"M\"] / len(gpt2_female_pred)))\n",
    "print(\"Distribution gpt2_female: \" + str(Counter(gpt2_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt2_18_24: \" + str(Counter(gpt2_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt2_25_34: \" + str(Counter(gpt2_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt2_35_49: \" + str(Counter(gpt2_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt2_50: \" + str(Counter(gpt2_50_pred)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio gemini2_male: 0.9811320754716981\n",
      "Distribution gemini2_male: Counter({'M': 52, 'F': 1})\n",
      "\n",
      "Male-ratio gemini2_female: 1.0\n",
      "Distribution gemini2_female: Counter({'M': 51})\n",
      "\n",
      "Distribution gemini2_18_24: Counter({'25-34': 51})\n",
      "\n",
      "Distribution gemini2_25_34: Counter({'25-34': 49, '35-49': 6})\n",
      "\n",
      "Distribution gemini2_35_49: Counter({'35-49': 47, '25-34': 3})\n",
      "\n",
      "Distribution gemini2_50: Counter({'25-34': 51})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gemini2_male_pred = model.predict(gemini2_male_features_combined)\n",
    "gemini2_female_pred = model.predict(gemini2_female_features_combined)\n",
    "gemini2_18_24_pred = model_age.predict(gemini2_18_24_features_combined)\n",
    "gemini2_25_34_pred = model_age.predict(gemini2_25_34_features_combined)\n",
    "gemini2_35_49_pred = model_age.predict(gemini2_35_49_features_combined)\n",
    "gemini2_50_pred = model_age.predict(gemini2_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio gemini2_male: \" + str(Counter(gemini2_male_pred)[\"M\"] / len(gemini2_male_pred)))\n",
    "print(\"Distribution gemini2_male: \" + str(Counter(gemini2_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio gemini2_female: \" + str(Counter(gemini2_female_pred)[\"M\"] / len(gemini2_female_pred)))\n",
    "print(\"Distribution gemini2_female: \" + str(Counter(gemini2_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini2_18_24: \" + str(Counter(gemini2_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini2_25_34: \" + str(Counter(gemini2_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini2_35_49: \" + str(Counter(gemini2_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini2_50: \" + str(Counter(gemini2_50_pred)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio llama2_male: 0.7547169811320755\n",
      "Distribution llama2_male: Counter({'M': 40, 'F': 13})\n",
      "\n",
      "Male-ratio llama2_female: 0.7543859649122807\n",
      "Distribution llama2_female: Counter({'M': 43, 'F': 14})\n",
      "\n",
      "Distribution llama2_18_24: Counter({'25-34': 47, '35-49': 4, '18-24': 4})\n",
      "\n",
      "Distribution llama2_25_34: Counter({'25-34': 48, '18-24': 8, '35-49': 5})\n",
      "\n",
      "Distribution llama2_35_49: Counter({'25-34': 42, '18-24': 13, '35-49': 4})\n",
      "\n",
      "Distribution llama2_50: Counter({'25-34': 54, '18-24': 11, '35-49': 5})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llama2_male_pred = model.predict(llama2_male_features_combined)\n",
    "llama2_female_pred = model.predict(llama2_female_features_combined)\n",
    "llama2_18_24_pred = model_age.predict(llama2_18_24_features_combined)\n",
    "llama2_25_34_pred = model_age.predict(llama2_25_34_features_combined)\n",
    "llama2_35_49_pred = model_age.predict(llama2_35_49_features_combined)\n",
    "llama2_50_pred = model_age.predict(llama2_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio llama2_male: \" + str(Counter(llama2_male_pred)[\"M\"] / len(llama2_male_pred)))\n",
    "print(\"Distribution llama2_male: \" + str(Counter(llama2_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio llama2_female: \" + str(Counter(llama2_female_pred)[\"M\"] / len(llama2_female_pred)))\n",
    "print(\"Distribution llama2_female: \" + str(Counter(llama2_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama2_18_24: \" + str(Counter(llama2_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama2_25_34: \" + str(Counter(llama2_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama2_35_49: \" + str(Counter(llama2_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama2_50: \" + str(Counter(llama2_50_pred)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_male_features = extract_features(df_gpt3_male, 'text')\n",
    "gpt3_female_features = extract_features(df_gpt3_female, 'text')\n",
    "gpt3_18_24_features = extract_features(df_gpt3_18_24, 'text')\n",
    "gpt3_25_34_features = extract_features(df_gpt3_25_34, 'text')\n",
    "gpt3_35_49_features = extract_features(df_gpt3_35_49, 'text')\n",
    "gpt3_50_features = extract_features(df_gpt3_50, 'text')\n",
    "\n",
    "gpt3_male_features_scaled = pd.DataFrame(scaler.transform(gpt3_male_features), columns=gpt3_male_features.columns)\n",
    "gpt3_female_features_scaled = pd.DataFrame(scaler.transform(gpt3_female_features), columns=gpt3_female_features.columns)\n",
    "gpt3_18_24_features_scaled = pd.DataFrame(scaler.transform(gpt3_18_24_features), columns=gpt3_18_24_features.columns)\n",
    "gpt3_25_34_features_scaled = pd.DataFrame(scaler.transform(gpt3_25_34_features), columns=gpt3_25_34_features.columns)\n",
    "gpt3_35_49_features_scaled = pd.DataFrame(scaler.transform(gpt3_35_49_features), columns=gpt3_35_49_features.columns)\n",
    "gpt3_50_features_scaled = pd.DataFrame(scaler.transform(gpt3_50_features), columns=gpt3_50_features.columns)\n",
    "\n",
    "gpt3_male_features_tfidf = combined_features.transform(df_gpt3_male['text'])\n",
    "gpt3_female_features_tfidf = combined_features.transform(df_gpt3_female['text'])\n",
    "gpt3_18_24_features_tfidf = combined_features.transform(df_gpt3_18_24['text'])\n",
    "gpt3_25_34_features_tfidf = combined_features.transform(df_gpt3_25_34['text'])\n",
    "gpt3_35_49_features_tfidf = combined_features.transform(df_gpt3_35_49['text'])\n",
    "gpt3_50_features_tfidf = combined_features.transform(df_gpt3_50['text'])\n",
    "\n",
    "gpt3_male_features_combined = hstack([gpt3_male_features_tfidf, csr_matrix(gpt3_male_features_scaled)])\n",
    "gpt3_female_features_combined = hstack([gpt3_female_features_tfidf, csr_matrix(gpt3_female_features_scaled)])\n",
    "gpt3_18_24_features_combined = hstack([gpt3_18_24_features_tfidf, csr_matrix(gpt3_18_24_features_scaled)])\n",
    "gpt3_25_34_features_combined = hstack([gpt3_25_34_features_tfidf, csr_matrix(gpt3_25_34_features_scaled)])\n",
    "gpt3_35_49_features_combined = hstack([gpt3_35_49_features_tfidf, csr_matrix(gpt3_35_49_features_scaled)])\n",
    "gpt3_50_features_combined = hstack([gpt3_50_features_tfidf, csr_matrix(gpt3_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini3_male_features = extract_features(df_gemini3_male, 'text')\n",
    "gemini3_female_features = extract_features(df_gemini3_female, 'text')\n",
    "gemini3_18_24_features = extract_features(df_gemini3_18_24, 'text')\n",
    "gemini3_25_34_features = extract_features(df_gemini3_25_34, 'text')\n",
    "gemini3_35_49_features = extract_features(df_gemini3_35_49, 'text')\n",
    "gemini3_50_features = extract_features(df_gemini3_50, 'text')\n",
    "\n",
    "gemini3_male_features_scaled = pd.DataFrame(scaler.transform(gemini3_male_features), columns=gemini3_male_features.columns)\n",
    "gemini3_female_features_scaled = pd.DataFrame(scaler.transform(gemini3_female_features), columns=gemini3_female_features.columns)\n",
    "gemini3_18_24_features_scaled = pd.DataFrame(scaler.transform(gemini3_18_24_features), columns=gemini3_18_24_features.columns)\n",
    "gemini3_25_34_features_scaled = pd.DataFrame(scaler.transform(gemini3_25_34_features), columns=gemini3_25_34_features.columns)\n",
    "gemini3_35_49_features_scaled = pd.DataFrame(scaler.transform(gemini3_35_49_features), columns=gemini3_35_49_features.columns)\n",
    "gemini3_50_features_scaled = pd.DataFrame(scaler.transform(gemini3_50_features), columns=gemini3_50_features.columns)\n",
    "\n",
    "gemini3_male_features_tfidf = combined_features.transform(df_gemini3_male['text'])\n",
    "gemini3_female_features_tfidf = combined_features.transform(df_gemini3_female['text'])\n",
    "gemini3_18_24_features_tfidf = combined_features.transform(df_gemini3_18_24['text'])\n",
    "gemini3_25_34_features_tfidf = combined_features.transform(df_gemini3_25_34['text'])\n",
    "gemini3_35_49_features_tfidf = combined_features.transform(df_gemini3_35_49['text'])\n",
    "gemini3_50_features_tfidf = combined_features.transform(df_gemini3_50['text'])\n",
    "\n",
    "gemini3_male_features_combined = hstack([gemini3_male_features_tfidf, csr_matrix(gemini3_male_features_scaled)])\n",
    "gemini3_female_features_combined = hstack([gemini3_female_features_tfidf, csr_matrix(gemini3_female_features_scaled)])\n",
    "gemini3_18_24_features_combined = hstack([gemini3_18_24_features_tfidf, csr_matrix(gemini3_18_24_features_scaled)])\n",
    "gemini3_25_34_features_combined = hstack([gemini3_25_34_features_tfidf, csr_matrix(gemini3_25_34_features_scaled)])\n",
    "gemini3_35_49_features_combined = hstack([gemini3_35_49_features_tfidf, csr_matrix(gemini3_35_49_features_scaled)])\n",
    "gemini3_50_features_combined = hstack([gemini3_50_features_tfidf, csr_matrix(gemini3_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_male_features = extract_features(df_llama3_male, 'text')\n",
    "llama3_female_features = extract_features(df_llama3_female, 'text')\n",
    "llama3_18_24_features = extract_features(df_llama3_18_24, 'text')\n",
    "llama3_25_34_features = extract_features(df_llama3_25_34, 'text')\n",
    "llama3_35_49_features = extract_features(df_llama3_35_49, 'text')\n",
    "llama3_50_features = extract_features(df_llama3_50, 'text')\n",
    "\n",
    "llama3_male_features_scaled = pd.DataFrame(scaler.transform(llama3_male_features), columns=llama3_male_features.columns)\n",
    "llama3_female_features_scaled = pd.DataFrame(scaler.transform(llama3_female_features), columns=llama3_female_features.columns)\n",
    "llama3_18_24_features_scaled = pd.DataFrame(scaler.transform(llama3_18_24_features), columns=llama3_18_24_features.columns)\n",
    "llama3_25_34_features_scaled = pd.DataFrame(scaler.transform(llama3_25_34_features), columns=llama3_25_34_features.columns)\n",
    "llama3_35_49_features_scaled = pd.DataFrame(scaler.transform(llama3_35_49_features), columns=llama3_35_49_features.columns)\n",
    "llama3_50_features_scaled = pd.DataFrame(scaler.transform(llama3_50_features), columns=llama3_50_features.columns)\n",
    "\n",
    "llama3_male_features_tfidf = combined_features.transform(df_llama3_male['text'])\n",
    "llama3_female_features_tfidf = combined_features.transform(df_llama3_female['text'])\n",
    "llama3_18_24_features_tfidf = combined_features.transform(df_llama3_18_24['text'])\n",
    "llama3_25_34_features_tfidf = combined_features.transform(df_llama3_25_34['text'])\n",
    "llama3_35_49_features_tfidf = combined_features.transform(df_llama3_35_49['text'])\n",
    "llama3_50_features_tfidf = combined_features.transform(df_llama3_50['text'])\n",
    "\n",
    "llama3_male_features_combined = hstack([llama3_male_features_tfidf, csr_matrix(llama3_male_features_scaled)])\n",
    "llama3_female_features_combined = hstack([llama3_female_features_tfidf, csr_matrix(llama3_female_features_scaled)])\n",
    "llama3_18_24_features_combined = hstack([llama3_18_24_features_tfidf, csr_matrix(llama3_18_24_features_scaled)])\n",
    "llama3_25_34_features_combined = hstack([llama3_25_34_features_tfidf, csr_matrix(llama3_25_34_features_scaled)])\n",
    "llama3_35_49_features_combined = hstack([llama3_35_49_features_tfidf, csr_matrix(llama3_35_49_features_scaled)])\n",
    "llama3_50_features_combined = hstack([llama3_50_features_tfidf, csr_matrix(llama3_50_features_scaled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio gpt3_male: 0.9433962264150944\n",
      "Distribution gpt3_male: Counter({'M': 50, 'F': 3})\n",
      "\n",
      "Male-ratio gpt3_female: 0.7166666666666667\n",
      "Distribution gpt3_female: Counter({'M': 43, 'F': 17})\n",
      "\n",
      "Distribution gpt3_18_24: Counter({'35-49': 45, '25-34': 8})\n",
      "\n",
      "Distribution gpt3_25_34: Counter({'25-34': 40, '35-49': 17, '18-24': 1})\n",
      "\n",
      "Distribution gpt3_35_49: Counter({'35-49': 45, '25-34': 8})\n",
      "\n",
      "Distribution gpt3_50: Counter({'35-49': 38, '18-24': 13, '25-34': 2, '50-XX': 2})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt3_male_pred = model.predict(gpt3_male_features_combined)\n",
    "gpt3_female_pred = model.predict(gpt3_female_features_combined)\n",
    "gpt3_18_24_pred = model_age.predict(gpt3_18_24_features_combined)\n",
    "gpt3_25_34_pred = model_age.predict(gpt3_25_34_features_combined)\n",
    "gpt3_35_49_pred = model_age.predict(gpt3_35_49_features_combined)\n",
    "gpt3_50_pred = model_age.predict(gpt3_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio gpt3_male: \" + str(Counter(gpt3_male_pred)[\"M\"] / len(gpt3_male_pred)))\n",
    "print(\"Distribution gpt3_male: \" + str(Counter(gpt3_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio gpt3_female: \" + str(Counter(gpt3_female_pred)[\"M\"] / len(gpt3_female_pred)))\n",
    "print(\"Distribution gpt3_female: \" + str(Counter(gpt3_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt3_18_24: \" + str(Counter(gpt3_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt3_25_34: \" + str(Counter(gpt3_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt3_35_49: \" + str(Counter(gpt3_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gpt3_50: \" + str(Counter(gpt3_50_pred)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio gemini3_male: 0.9607843137254902\n",
      "Distribution gemini3_male: Counter({'M': 49, 'F': 2})\n",
      "\n",
      "Male-ratio gemini3_female: 0.8627450980392157\n",
      "Distribution gemini3_female: Counter({'M': 44, 'F': 7})\n",
      "\n",
      "Distribution gemini3_18_24: Counter({'25-34': 27, '35-49': 24})\n",
      "\n",
      "Distribution gemini3_25_34: Counter({'25-34': 50, '35-49': 3})\n",
      "\n",
      "Distribution gemini3_35_49: Counter({'25-34': 50, '35-49': 3})\n",
      "\n",
      "Distribution gemini3_50: Counter({'25-34': 52, '35-49': 5})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gemini3_male_pred = model.predict(gemini3_male_features_combined)\n",
    "gemini3_female_pred = model.predict(gemini3_female_features_combined)\n",
    "gemini3_18_24_pred = model_age.predict(gemini3_18_24_features_combined)\n",
    "gemini3_25_34_pred = model_age.predict(gemini3_25_34_features_combined)\n",
    "gemini3_35_49_pred = model_age.predict(gemini3_35_49_features_combined)\n",
    "gemini3_50_pred = model_age.predict(gemini3_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio gemini3_male: \" + str(Counter(gemini3_male_pred)[\"M\"] / len(gemini3_male_pred)))\n",
    "print(\"Distribution gemini3_male: \" + str(Counter(gemini3_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio gemini3_female: \" + str(Counter(gemini3_female_pred)[\"M\"] / len(gemini3_female_pred)))\n",
    "print(\"Distribution gemini3_female: \" + str(Counter(gemini3_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini3_18_24: \" + str(Counter(gemini3_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini3_25_34: \" + str(Counter(gemini3_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini3_35_49: \" + str(Counter(gemini3_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution gemini3_50: \" + str(Counter(gemini3_50_pred)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male-ratio llama3_male: 0.5483870967741935\n",
      "Distribution llama3_male: Counter({'M': 34, 'F': 28})\n",
      "\n",
      "Male-ratio llama3_female: 0.11475409836065574\n",
      "Distribution llama3_female: Counter({'F': 54, 'M': 7})\n",
      "\n",
      "Distribution llama3_18_24: Counter({'18-24': 45, '35-49': 9, '50-XX': 5, '25-34': 3})\n",
      "\n",
      "Distribution llama3_25_34: Counter({'25-34': 33, '35-49': 28, '18-24': 6, '50-XX': 1})\n",
      "\n",
      "Distribution llama3_35_49: Counter({'25-34': 36, '35-49': 22, '18-24': 3})\n",
      "\n",
      "Distribution llama3_50: Counter({'50-XX': 33, '35-49': 18, '25-34': 3})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llama3_male_pred = model.predict(llama3_male_features_combined)\n",
    "llama3_female_pred = model.predict(llama3_female_features_combined)\n",
    "llama3_18_24_pred = model_age.predict(llama3_18_24_features_combined)\n",
    "llama3_25_34_pred = model_age.predict(llama3_25_34_features_combined)\n",
    "llama3_35_49_pred = model_age.predict(llama3_35_49_features_combined)\n",
    "llama3_50_pred = model_age.predict(llama3_50_features_combined)\n",
    "\n",
    "print(\"Male-ratio llama3_male: \" + str(Counter(llama3_male_pred)[\"M\"] / len(llama3_male_pred)))\n",
    "print(\"Distribution llama3_male: \" + str(Counter(llama3_male_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Male-ratio llama3_female: \" + str(Counter(llama3_female_pred)[\"M\"] / len(llama3_female_pred)))\n",
    "print(\"Distribution llama3_female: \" + str(Counter(llama3_female_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama3_18_24: \" + str(Counter(llama3_18_24_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama3_25_34: \" + str(Counter(llama3_25_34_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama3_35_49: \" + str(Counter(llama3_35_49_pred)) + \"\\n\")\n",
    "\n",
    "print(\"Distribution llama3_50: \" + str(Counter(llama3_50_pred)) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
