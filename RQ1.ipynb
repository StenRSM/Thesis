{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering research question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pan15_train = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_training.csv')\n",
    "data_pan15_test = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\raw_data\\PAN_15_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train = data_pan15_train.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()\n",
    "combined_pan15_test = data_pan15_test.groupby('author').agg({\n",
    "    'text': ' '.join,\n",
    "    'gender': 'first',\n",
    "    'age': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gpt1.csv')\n",
    "df_gemini = pd.read_csv(r'C:\\Users\\Sten\\Documents\\EUR BIM\\thesis\\data\\data\\gemini1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Character-based features\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def alphabetic_ratio(text):\n",
    "    alphabetic = sum(c.isalpha() for c in text)\n",
    "    return alphabetic/len(text)\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    upper = sum(c.isupper() for c in text)\n",
    "    return upper/len(text)\n",
    "\n",
    "def digit_ratio(text):\n",
    "    digit = sum(c.isdigit() for c in text)\n",
    "    return digit/len(text)\n",
    "\n",
    "def whitespace_ratio(text):\n",
    "    whitespace = sum(c.isspace() for c in text)\n",
    "    return whitespace/len(text)\n",
    "\n",
    "def tab_ratio(text):\n",
    "    tabs = text.count('\\t')\n",
    "    return tabs/len(text)\n",
    "\n",
    "def letter_ratio(text, letter):\n",
    "    text = text.lower()\n",
    "    letter_count = text.count(letter)\n",
    "    return letter_count/len(text)\n",
    "\n",
    "def specialcharacter_ratio(text, character):\n",
    "    spec_count = text.count(character)\n",
    "    return spec_count/len(text)\n",
    "\n",
    "# Word-based features\n",
    "def number_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n",
    "def word_length(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length/num_words\n",
    "\n",
    "def vocabulary_richness(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_uniq_words = len(set(words))\n",
    "    return num_uniq_words/num_words\n",
    "\n",
    "def long_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    long_words_list = [word for word in words if len(word) > 6]\n",
    "    return len(long_words_list)/len(words)\n",
    "\n",
    "def short_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words_list = [word for word in words if 1 <= len(word) <= 3]\n",
    "    return len(short_words_list)/len(words)\n",
    "\n",
    "def legomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    return len(legomena)/len(words)\n",
    "\n",
    "def dislegomena(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    return len(dislegomena)/len(words)\n",
    "\n",
    "def yules_k(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    Vi = FreqDist(freq.values())\n",
    "    K = 10**4 * ((-N + sum(i**2 * Vi[i] for i in Vi))/N**2)\n",
    "    return K\n",
    "\n",
    "def simpson_d(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    if N < 2:\n",
    "        return 0\n",
    "    D = sum(fr * (fr - 1) / (N * (N - 1)) for fr in freq.values())\n",
    "    return D\n",
    "\n",
    "def sichel_s(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    dislegomena = [word for word in freq if freq[word] == 2]\n",
    "    S = len(dislegomena)/len(freq.values())\n",
    "    return S\n",
    "\n",
    "def honores_r(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    if not words:\n",
    "        return 0\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    V = len(freq.values())\n",
    "    legomena = [word for word in freq if freq[word] == 1]\n",
    "    unique_count_ratio = len(legomena) / V if V > 0 else 0\n",
    "    if unique_count_ratio == 1 or N == 0:\n",
    "        return 0\n",
    "    R = (100*np.log(N)/(1-(len(legomena)/V)))\n",
    "    return R\n",
    "\n",
    "def entropy(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    freq = FreqDist(words)\n",
    "    N = len(words)\n",
    "    E = -sum((fr / N) * np.log(fr/N) for fr in freq.values())\n",
    "    return E\n",
    "\n",
    "# Syntatic features\n",
    "def punctuations_ratio(text, punctuation):\n",
    "    punctuation_list = re.findall(punctuation, text)\n",
    "    return len(punctuation_list)/len(text)\n",
    "\n",
    "# Structural features\n",
    "def lines(text):\n",
    "    return len(text.split('\\n'))\n",
    "\n",
    "def sentences(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "def paragraphs(text):\n",
    "    return len([par for par in text.split('\\n\\n') if par.strip()])\n",
    "\n",
    "def sentence_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(sent_tokenize(par)) for par in pars])\n",
    "\n",
    "def words_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(re.findall(r'\\b\\w+\\b', par)) for par in pars])\n",
    "\n",
    "def chars_paragraph(text):\n",
    "    pars = [par for par in text.split('\\n\\n') if par.strip()]\n",
    "    return statistics.mean([len(par) for par in pars])\n",
    "\n",
    "def words_sentences(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return statistics.mean([len(word_tokenize(sentence)) for sentence in sents])\n",
    "\n",
    "def uppercase_start(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    return (sum(1 for sentence in sents if sentence[0].isupper()) / len(sents))\n",
    "\n",
    "def extract_features(dataframe, text_column):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Character-based features\n",
    "    features['total_characters'] = dataframe[text_column].apply(character_count)\n",
    "    features['ratio_alphabetic'] = dataframe[text_column].apply(alphabetic_ratio)\n",
    "    features['ratio_uppercase'] = dataframe[text_column].apply(uppercase_ratio)\n",
    "    features['ratio_digit'] = dataframe[text_column].apply(digit_ratio)\n",
    "    features['ratio_whitespace'] = dataframe[text_column].apply(whitespace_ratio)\n",
    "    features['ratio_tabspace'] = dataframe[text_column].apply(tab_ratio)\n",
    "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for letter in letters:\n",
    "        features[letter+'_frequency'] = dataframe[text_column].apply(letter_ratio, args=(letter,))\n",
    "    special_characters = ['~', '@', '#', '$', '%', '^', '&', '*', '-', '_', '=', '+', '>', '<', '[', ']', '{', '}', '/', '\\\\', '|']\n",
    "    for character in special_characters:\n",
    "        features[character+'_frequency'] = dataframe[text_column].apply(specialcharacter_ratio, args=(character,))\n",
    "    \n",
    "    # Word-based features\n",
    "    features['total_words'] = dataframe[text_column].apply(number_words)\n",
    "    features['word_length'] = dataframe[text_column].apply(word_length)\n",
    "    features['vocabulary_richness'] = dataframe[text_column].apply(vocabulary_richness)\n",
    "    features['long_words'] = dataframe[text_column].apply(long_words)\n",
    "    features['short_words'] = dataframe[text_column].apply(short_words)\n",
    "    features['hapax_legomena'] = dataframe[text_column].apply(legomena)\n",
    "    features['hapax_dislegomena'] = dataframe[text_column].apply(dislegomena)\n",
    "    features['yules_k'] = dataframe[text_column].apply(yules_k)\n",
    "    features['simpson_d'] = dataframe[text_column].apply(simpson_d)\n",
    "    features['sichel_s'] = dataframe[text_column].apply(sichel_s)\n",
    "    #features['honore_r'] = dataframe[text_column].apply(honores_r)\n",
    "    features['entropy'] =  dataframe[text_column].apply(entropy)\n",
    "    # Brunet W?\n",
    "    # word length frequency distribution\n",
    "\n",
    "    \n",
    "    # Syntactic features\n",
    "    punctuations = [r\"’\", r\",\", r\"\\.\", r\":\", r\";\", r\"\\?\", r\"\\?{2,}\", r\"!\", r\"!{2,}\", r\"\\.{3}\"]\n",
    "    for punctuation in punctuations:\n",
    "        features[punctuation+\"_frequency\"] = dataframe[text_column].apply(punctuations_ratio, args=(punctuation,))\n",
    "\n",
    "    # Structural features\n",
    "    features['number_lines'] = dataframe[text_column].apply(lines)\n",
    "    features['number_sentences'] = dataframe[text_column].apply(sentences)\n",
    "    features['number_paragraphs'] = dataframe[text_column].apply(paragraphs)\n",
    "    features['sentences_per_paragraph'] = dataframe[text_column].apply(sentence_paragraph)\n",
    "    features['word_per_paragraph'] = dataframe[text_column].apply(words_paragraph)\n",
    "    features['character_per_paragraph'] = dataframe[text_column].apply(chars_paragraph)\n",
    "    features['word_per_sentence'] = dataframe[text_column].apply(words_sentences)\n",
    "    features['ratio_sentencestart_uppercase'] = dataframe[text_column].apply(uppercase_start)\n",
    "    #features['gender'] = dataframe['gender']\n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pan15_train_features = extract_features(combined_pan15_train, 'text')\n",
    "combined_pan15_test_features = extract_features(combined_pan15_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "combined_pan15_train_features_scaled = pd.DataFrame(scaler.fit_transform(combined_pan15_train_features), columns=combined_pan15_train_features.columns)\n",
    "combined_pan15_test_features_scaled = pd.DataFrame(scaler.transform(combined_pan15_test_features), columns=combined_pan15_test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_pan15_train_features_scaled\n",
    "X_test = combined_pan15_test_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = combined_pan15_train['gender']\n",
    "y_test = combined_pan15_test['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=0.01, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.01, max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=0.01, max_iter=10000)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=10000, C= 0.01, class_weight= None, loss= 'squared_hinge', tol= 0.0001)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7535211267605634"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), sublinear_tf=True, min_df=2)\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), sublinear_tf=True, min_df=2)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('char', char_vectorizer),\n",
    "    ('word', word_vectorizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features_train = combined_features.fit_transform(combined_pan15_train['text'])\n",
    "tfidf_features_test =  combined_features.transform(combined_pan15_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([tfidf_features_train, csr_matrix(combined_pan15_train_features_scaled)])\n",
    "X_test = hstack([tfidf_features_test, csr_matrix(combined_pan15_test_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n",
      "Precision: 0.743\n",
      "Recall: 0.775\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=10000, C= 0.01, class_weight= None, loss= 'squared_hinge', tol= 0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred, pos_label='F'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred, pos_label='F'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.754\n",
      "Precision: 0.725\n",
      "Recall: 0.817\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_lr), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_lr, pos_label='F'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred_lr, pos_label='F'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.725\n",
      "Precision: 0.716\n",
      "Recall: 0.746\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_rf), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_rf, pos_label='F'), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred_rf, pos_label='F'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<152x164169 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1463113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting LLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features = extract_features(df_gpt, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features_scaled = pd.DataFrame(scaler.transform(gpt_features), columns=gpt_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 82 features, but LinearSVC is expecting 164169 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gpt_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt_features_scaled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:420\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 420\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    422\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    398\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    399\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 401\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 82 features, but LinearSVC is expecting 164169 features as input."
     ]
    }
   ],
   "source": [
    "gpt_pred = model.predict(gpt_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'M': 109, 'F': 141})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'F', 'M', 'M', 'M', 'F', 'M', 'M', 'M', 'M', 'F', 'M', 'M',\n",
       "       'M', 'M', 'M', 'F', 'M', 'M', 'M', 'F', 'M', 'M', 'F', 'M', 'F',\n",
       "       'F', 'F', 'M', 'F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'F', 'F',\n",
       "       'F', 'M', 'M', 'F', 'F', 'F', 'M', 'F', 'M', 'F', 'F', 'F', 'M',\n",
       "       'F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F', 'F', 'M', 'M',\n",
       "       'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F', 'M', 'F', 'M', 'M', 'F',\n",
       "       'F', 'M', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F', 'M', 'F',\n",
       "       'M', 'F', 'M', 'M', 'F', 'M', 'F', 'F', 'M', 'M', 'F', 'M', 'F',\n",
       "       'M', 'M', 'F', 'F', 'M', 'F', 'F', 'M', 'M', 'F', 'M', 'F', 'F',\n",
       "       'M', 'M', 'F', 'M', 'F', 'F', 'M', 'M', 'F', 'M', 'F', 'M', 'M',\n",
       "       'M', 'F', 'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'M',\n",
       "       'F', 'F', 'M', 'F', 'M', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'M',\n",
       "       'F', 'M', 'F', 'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'F',\n",
       "       'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F',\n",
       "       'F', 'F', 'M', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'F', 'M',\n",
       "       'M', 'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'F', 'M', 'F',\n",
       "       'M', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'F',\n",
       "       'F', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'F', 'M', 'F', 'F', 'M',\n",
       "       'F', 'F', 'F', 'F', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'F',\n",
       "       'F', 'F', 'F'], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_features = extract_features(df_gemini, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_features_scaled = pd.DataFrame(scaler.fit_transform(gemini_features), columns=gemini_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 82 features, but LinearSVC is expecting 164169 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gemini_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgemini_features_scaled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:420\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 420\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    422\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:401\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    398\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    399\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 401\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Sten\\AppData\\Local\\R-MINI~1\\envs\\python39\\lib\\site-packages\\sklearn\\base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 82 features, but LinearSVC is expecting 164169 features as input."
     ]
    }
   ],
   "source": [
    "gemini_pred = model.predict(gemini_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gemini_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Counter(\u001b[43mgemini_pred\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gemini_pred' is not defined"
     ]
    }
   ],
   "source": [
    "Counter(gemini_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_characters</th>\n",
       "      <th>ratio_alphabetic</th>\n",
       "      <th>ratio_uppercase</th>\n",
       "      <th>ratio_digit</th>\n",
       "      <th>ratio_whitespace</th>\n",
       "      <th>ratio_tabspace</th>\n",
       "      <th>a_frequency</th>\n",
       "      <th>b_frequency</th>\n",
       "      <th>c_frequency</th>\n",
       "      <th>d_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>!{2,}_frequency</th>\n",
       "      <th>\\.{3}_frequency</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>number_sentences</th>\n",
       "      <th>number_paragraphs</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>word_per_paragraph</th>\n",
       "      <th>character_per_paragraph</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>ratio_sentencestart_uppercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.537847</td>\n",
       "      <td>-2.870541</td>\n",
       "      <td>1.533162</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>1.936818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.420483</td>\n",
       "      <td>0.544050</td>\n",
       "      <td>0.029489</td>\n",
       "      <td>-0.591686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320620</td>\n",
       "      <td>2.519023</td>\n",
       "      <td>2.537847</td>\n",
       "      <td>-2.143724</td>\n",
       "      <td>1.998703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.421016</td>\n",
       "      <td>-2.407078</td>\n",
       "      <td>-0.302430</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>2.209718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.767916</td>\n",
       "      <td>0.984258</td>\n",
       "      <td>0.214907</td>\n",
       "      <td>0.536856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.186978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.186978</td>\n",
       "      <td>2.861480</td>\n",
       "      <td>2.421016</td>\n",
       "      <td>-1.407426</td>\n",
       "      <td>2.044244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.638248</td>\n",
       "      <td>-2.884950</td>\n",
       "      <td>1.248158</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>3.366712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151419</td>\n",
       "      <td>1.967440</td>\n",
       "      <td>-2.189132</td>\n",
       "      <td>0.373271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.153567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.153567</td>\n",
       "      <td>2.359209</td>\n",
       "      <td>1.638248</td>\n",
       "      <td>-1.199004</td>\n",
       "      <td>0.827662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.038516</td>\n",
       "      <td>-2.144681</td>\n",
       "      <td>-0.473977</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>1.896953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.459126</td>\n",
       "      <td>-0.108360</td>\n",
       "      <td>-1.395644</td>\n",
       "      <td>-1.257025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636862</td>\n",
       "      <td>1.331836</td>\n",
       "      <td>1.038516</td>\n",
       "      <td>-1.208947</td>\n",
       "      <td>1.657149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.591516</td>\n",
       "      <td>-2.481022</td>\n",
       "      <td>-0.766962</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>2.152108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.939128</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>-0.209004</td>\n",
       "      <td>0.177763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.186978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.186978</td>\n",
       "      <td>1.948260</td>\n",
       "      <td>1.591516</td>\n",
       "      <td>-1.618793</td>\n",
       "      <td>2.044244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.266096</td>\n",
       "      <td>0.577826</td>\n",
       "      <td>0.130744</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>-0.753723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250395</td>\n",
       "      <td>0.569119</td>\n",
       "      <td>-1.113973</td>\n",
       "      <td>-1.179941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>-0.334792</td>\n",
       "      <td>-0.266096</td>\n",
       "      <td>0.275780</td>\n",
       "      <td>-0.665415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.146707</td>\n",
       "      <td>0.821527</td>\n",
       "      <td>-1.351670</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>-0.720373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.319365</td>\n",
       "      <td>0.509908</td>\n",
       "      <td>0.923525</td>\n",
       "      <td>-0.746799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>-0.037995</td>\n",
       "      <td>0.146707</td>\n",
       "      <td>0.670161</td>\n",
       "      <td>-0.665415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.293357</td>\n",
       "      <td>0.259872</td>\n",
       "      <td>-1.250403</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>-0.421717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.114009</td>\n",
       "      <td>-1.094035</td>\n",
       "      <td>-0.328616</td>\n",
       "      <td>0.726827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>-0.334792</td>\n",
       "      <td>-0.293357</td>\n",
       "      <td>0.322178</td>\n",
       "      <td>-0.665415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-0.569856</td>\n",
       "      <td>0.915314</td>\n",
       "      <td>2.856036</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>-0.957574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.454568</td>\n",
       "      <td>-0.945358</td>\n",
       "      <td>-0.614918</td>\n",
       "      <td>1.426485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>-0.631589</td>\n",
       "      <td>-0.569856</td>\n",
       "      <td>-0.049004</td>\n",
       "      <td>-0.665415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.223258</td>\n",
       "      <td>-0.484043</td>\n",
       "      <td>-0.673463</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>0.114591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.620773</td>\n",
       "      <td>1.852705</td>\n",
       "      <td>-0.218589</td>\n",
       "      <td>0.429764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>-0.197809</td>\n",
       "      <td>-0.223258</td>\n",
       "      <td>0.577365</td>\n",
       "      <td>-0.665415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_characters  ratio_alphabetic  ratio_uppercase  ratio_digit  \\\n",
       "0            2.537847         -2.870541         1.533162    -0.085749   \n",
       "1            2.421016         -2.407078        -0.302430    -0.085749   \n",
       "2            1.638248         -2.884950         1.248158    -0.085749   \n",
       "3            1.038516         -2.144681        -0.473977    -0.085749   \n",
       "4            1.591516         -2.481022        -0.766962    -0.085749   \n",
       "..                ...               ...              ...          ...   \n",
       "132         -0.266096          0.577826         0.130744    -0.085749   \n",
       "133          0.146707          0.821527        -1.351670    -0.085749   \n",
       "134         -0.293357          0.259872        -1.250403    -0.085749   \n",
       "135         -0.569856          0.915314         2.856036    -0.085749   \n",
       "136         -0.223258         -0.484043        -0.673463    -0.085749   \n",
       "\n",
       "     ratio_whitespace  ratio_tabspace  a_frequency  b_frequency  c_frequency  \\\n",
       "0            1.936818             0.0    -0.420483     0.544050     0.029489   \n",
       "1            2.209718             0.0    -0.767916     0.984258     0.214907   \n",
       "2            3.366712             0.0     0.151419     1.967440    -2.189132   \n",
       "3            1.896953             0.0    -0.459126    -0.108360    -1.395644   \n",
       "4            2.152108             0.0    -0.939128     0.266312    -0.209004   \n",
       "..                ...             ...          ...          ...          ...   \n",
       "132         -0.753723             0.0     1.250395     0.569119    -1.113973   \n",
       "133         -0.720373             0.0    -0.319365     0.509908     0.923525   \n",
       "134         -0.421717             0.0    -0.114009    -1.094035    -0.328616   \n",
       "135         -0.957574             0.0    -0.454568    -0.945358    -0.614918   \n",
       "136          0.114591             0.0     1.620773     1.852705    -0.218589   \n",
       "\n",
       "     d_frequency  ...  !{2,}_frequency  \\.{3}_frequency  number_lines  \\\n",
       "0      -0.591686  ...              0.0              0.0           0.0   \n",
       "1       0.536856  ...              0.0              0.0           0.0   \n",
       "2       0.373271  ...              0.0              0.0           0.0   \n",
       "3      -1.257025  ...              0.0              0.0           0.0   \n",
       "4       0.177763  ...              0.0              0.0           0.0   \n",
       "..           ...  ...              ...              ...           ...   \n",
       "132    -1.179941  ...              0.0              0.0           0.0   \n",
       "133    -0.746799  ...              0.0              0.0           0.0   \n",
       "134     0.726827  ...              0.0              0.0           0.0   \n",
       "135     1.426485  ...              0.0              0.0           0.0   \n",
       "136     0.429764  ...              0.0              0.0           0.0   \n",
       "\n",
       "     number_sentences  number_paragraphs  sentences_per_paragraph  \\\n",
       "0            7.320620                0.0                 7.320620   \n",
       "1            3.186978                0.0                 3.186978   \n",
       "2            2.153567                0.0                 2.153567   \n",
       "3            1.636862                0.0                 1.636862   \n",
       "4            3.186978                0.0                 3.186978   \n",
       "..                ...                ...                      ...   \n",
       "132         -0.429959                0.0                -0.429959   \n",
       "133         -0.429959                0.0                -0.429959   \n",
       "134         -0.429959                0.0                -0.429959   \n",
       "135         -0.429959                0.0                -0.429959   \n",
       "136         -0.429959                0.0                -0.429959   \n",
       "\n",
       "     word_per_paragraph  character_per_paragraph  word_per_sentence  \\\n",
       "0              2.519023                 2.537847          -2.143724   \n",
       "1              2.861480                 2.421016          -1.407426   \n",
       "2              2.359209                 1.638248          -1.199004   \n",
       "3              1.331836                 1.038516          -1.208947   \n",
       "4              1.948260                 1.591516          -1.618793   \n",
       "..                  ...                      ...                ...   \n",
       "132           -0.334792                -0.266096           0.275780   \n",
       "133           -0.037995                 0.146707           0.670161   \n",
       "134           -0.334792                -0.293357           0.322178   \n",
       "135           -0.631589                -0.569856          -0.049004   \n",
       "136           -0.197809                -0.223258           0.577365   \n",
       "\n",
       "     ratio_sentencestart_uppercase  \n",
       "0                         1.998703  \n",
       "1                         2.044244  \n",
       "2                         0.827662  \n",
       "3                         1.657149  \n",
       "4                         2.044244  \n",
       "..                             ...  \n",
       "132                      -0.665415  \n",
       "133                      -0.665415  \n",
       "134                      -0.665415  \n",
       "135                      -0.665415  \n",
       "136                      -0.665415  \n",
       "\n",
       "[137 rows x 82 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_characters</th>\n",
       "      <th>ratio_alphabetic</th>\n",
       "      <th>ratio_uppercase</th>\n",
       "      <th>ratio_digit</th>\n",
       "      <th>ratio_whitespace</th>\n",
       "      <th>ratio_tabspace</th>\n",
       "      <th>a_frequency</th>\n",
       "      <th>b_frequency</th>\n",
       "      <th>c_frequency</th>\n",
       "      <th>d_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>!{2,}_frequency</th>\n",
       "      <th>\\.{3}_frequency</th>\n",
       "      <th>number_lines</th>\n",
       "      <th>number_sentences</th>\n",
       "      <th>number_paragraphs</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>word_per_paragraph</th>\n",
       "      <th>character_per_paragraph</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>ratio_sentencestart_uppercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.300641</td>\n",
       "      <td>3.588769</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>-1.505044</td>\n",
       "      <td>-1.080866</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.009045</td>\n",
       "      <td>-0.777722</td>\n",
       "      <td>-0.776379</td>\n",
       "      <td>4.347600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.276310</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.102070</td>\n",
       "      <td>-1.532015</td>\n",
       "      <td>-1.443390</td>\n",
       "      <td>0.189019</td>\n",
       "      <td>0.016981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.371937</td>\n",
       "      <td>3.867174</td>\n",
       "      <td>-1.586585</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.086958</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.273053</td>\n",
       "      <td>-2.088889</td>\n",
       "      <td>-0.072512</td>\n",
       "      <td>3.326807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.383305</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.218635</td>\n",
       "      <td>-1.605638</td>\n",
       "      <td>-1.500535</td>\n",
       "      <td>1.230736</td>\n",
       "      <td>0.823698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.372356</td>\n",
       "      <td>3.576506</td>\n",
       "      <td>-1.735803</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-0.899938</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.379058</td>\n",
       "      <td>-1.096225</td>\n",
       "      <td>0.705938</td>\n",
       "      <td>3.332185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.365473</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.199208</td>\n",
       "      <td>-1.601431</td>\n",
       "      <td>-1.500871</td>\n",
       "      <td>0.894019</td>\n",
       "      <td>-0.655283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.364388</td>\n",
       "      <td>3.782512</td>\n",
       "      <td>-1.576787</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-0.989821</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>-0.221008</td>\n",
       "      <td>-1.875153</td>\n",
       "      <td>-0.642413</td>\n",
       "      <td>4.738412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.418970</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.257490</td>\n",
       "      <td>-1.597224</td>\n",
       "      <td>-1.494484</td>\n",
       "      <td>2.682825</td>\n",
       "      <td>-0.655283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.386196</td>\n",
       "      <td>3.443498</td>\n",
       "      <td>-1.726003</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-0.943442</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.088378</td>\n",
       "      <td>-0.766340</td>\n",
       "      <td>-0.406108</td>\n",
       "      <td>3.685398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.311975</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.140925</td>\n",
       "      <td>-1.609845</td>\n",
       "      <td>-1.511964</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>-1.887767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-2.406746</td>\n",
       "      <td>4.448035</td>\n",
       "      <td>-2.250283</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.313927</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.723779</td>\n",
       "      <td>-1.416760</td>\n",
       "      <td>-0.242465</td>\n",
       "      <td>2.731020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.454635</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.296345</td>\n",
       "      <td>-1.639293</td>\n",
       "      <td>-1.528435</td>\n",
       "      <td>8.806854</td>\n",
       "      <td>3.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-2.426037</td>\n",
       "      <td>4.265779</td>\n",
       "      <td>-2.214060</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.222449</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.087720</td>\n",
       "      <td>-0.245548</td>\n",
       "      <td>-0.492761</td>\n",
       "      <td>3.344958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.454635</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.296345</td>\n",
       "      <td>-1.645604</td>\n",
       "      <td>-1.543897</td>\n",
       "      <td>8.775287</td>\n",
       "      <td>3.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-2.417230</td>\n",
       "      <td>4.311095</td>\n",
       "      <td>-2.179401</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.322574</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>-0.216587</td>\n",
       "      <td>-0.833784</td>\n",
       "      <td>-0.197470</td>\n",
       "      <td>2.865185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.454635</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.296345</td>\n",
       "      <td>-1.641397</td>\n",
       "      <td>-1.536838</td>\n",
       "      <td>8.806854</td>\n",
       "      <td>3.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-2.404229</td>\n",
       "      <td>4.499228</td>\n",
       "      <td>-2.250343</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.382755</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>-0.913124</td>\n",
       "      <td>-0.172029</td>\n",
       "      <td>3.758954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.454635</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.296345</td>\n",
       "      <td>-1.641397</td>\n",
       "      <td>-1.526418</td>\n",
       "      <td>8.712153</td>\n",
       "      <td>3.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-2.403810</td>\n",
       "      <td>4.379240</td>\n",
       "      <td>-2.215685</td>\n",
       "      <td>-1.557759</td>\n",
       "      <td>-1.242638</td>\n",
       "      <td>-3.423313</td>\n",
       "      <td>1.467571</td>\n",
       "      <td>0.376101</td>\n",
       "      <td>-0.011842</td>\n",
       "      <td>3.929590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.726474</td>\n",
       "      <td>-0.420531</td>\n",
       "      <td>-1.454635</td>\n",
       "      <td>-0.244418</td>\n",
       "      <td>-1.296345</td>\n",
       "      <td>-1.630879</td>\n",
       "      <td>-1.526082</td>\n",
       "      <td>8.933123</td>\n",
       "      <td>3.042169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_characters  ratio_alphabetic  ratio_uppercase  ratio_digit  \\\n",
       "0           -2.300641          3.588769        -1.690213    -1.505044   \n",
       "1           -2.371937          3.867174        -1.586585    -1.557759   \n",
       "2           -2.372356          3.576506        -1.735803    -1.557759   \n",
       "3           -2.364388          3.782512        -1.576787    -1.557759   \n",
       "4           -2.386196          3.443498        -1.726003    -1.557759   \n",
       "..                ...               ...              ...          ...   \n",
       "245         -2.406746          4.448035        -2.250283    -1.557759   \n",
       "246         -2.426037          4.265779        -2.214060    -1.557759   \n",
       "247         -2.417230          4.311095        -2.179401    -1.557759   \n",
       "248         -2.404229          4.499228        -2.250343    -1.557759   \n",
       "249         -2.403810          4.379240        -2.215685    -1.557759   \n",
       "\n",
       "     ratio_whitespace  ratio_tabspace  a_frequency  b_frequency  c_frequency  \\\n",
       "0           -1.080866       -3.423313     1.009045    -0.777722    -0.776379   \n",
       "1           -1.086958       -3.423313     1.273053    -2.088889    -0.072512   \n",
       "2           -0.899938       -3.423313     1.379058    -1.096225     0.705938   \n",
       "3           -0.989821       -3.423313    -0.221008    -1.875153    -0.642413   \n",
       "4           -0.943442       -3.423313     1.088378    -0.766340    -0.406108   \n",
       "..                ...             ...          ...          ...          ...   \n",
       "245         -1.313927       -3.423313     1.723779    -1.416760    -0.242465   \n",
       "246         -1.222449       -3.423313     1.087720    -0.245548    -0.492761   \n",
       "247         -1.322574       -3.423313    -0.216587    -0.833784    -0.197470   \n",
       "248         -1.382755       -3.423313     0.538793    -0.913124    -0.172029   \n",
       "249         -1.242638       -3.423313     1.467571     0.376101    -0.011842   \n",
       "\n",
       "     d_frequency  ...  !{2,}_frequency  \\.{3}_frequency  number_lines  \\\n",
       "0       4.347600  ...        -0.615171        -0.726474     -0.420531   \n",
       "1       3.326807  ...        -0.615171        -0.726474     -0.420531   \n",
       "2       3.332185  ...        -0.615171        -0.726474     -0.420531   \n",
       "3       4.738412  ...        -0.615171        -0.726474     -0.420531   \n",
       "4       3.685398  ...        -0.615171        -0.726474     -0.420531   \n",
       "..           ...  ...              ...              ...           ...   \n",
       "245     2.731020  ...        -0.615171        -0.726474     -0.420531   \n",
       "246     3.344958  ...        -0.615171        -0.726474     -0.420531   \n",
       "247     2.865185  ...        -0.615171        -0.726474     -0.420531   \n",
       "248     3.758954  ...        -0.615171        -0.726474     -0.420531   \n",
       "249     3.929590  ...        -0.615171        -0.726474     -0.420531   \n",
       "\n",
       "     number_sentences  number_paragraphs  sentences_per_paragraph  \\\n",
       "0           -1.276310          -0.244418                -1.102070   \n",
       "1           -1.383305          -0.244418                -1.218635   \n",
       "2           -1.365473          -0.244418                -1.199208   \n",
       "3           -1.418970          -0.244418                -1.257490   \n",
       "4           -1.311975          -0.244418                -1.140925   \n",
       "..                ...                ...                      ...   \n",
       "245         -1.454635          -0.244418                -1.296345   \n",
       "246         -1.454635          -0.244418                -1.296345   \n",
       "247         -1.454635          -0.244418                -1.296345   \n",
       "248         -1.454635          -0.244418                -1.296345   \n",
       "249         -1.454635          -0.244418                -1.296345   \n",
       "\n",
       "     word_per_paragraph  character_per_paragraph  word_per_sentence  \\\n",
       "0             -1.532015                -1.443390           0.189019   \n",
       "1             -1.605638                -1.500535           1.230736   \n",
       "2             -1.601431                -1.500871           0.894019   \n",
       "3             -1.597224                -1.494484           2.682825   \n",
       "4             -1.609845                -1.511964           0.283721   \n",
       "..                  ...                      ...                ...   \n",
       "245           -1.639293                -1.528435           8.806854   \n",
       "246           -1.645604                -1.543897           8.775287   \n",
       "247           -1.641397                -1.536838           8.806854   \n",
       "248           -1.641397                -1.526418           8.712153   \n",
       "249           -1.630879                -1.526082           8.933123   \n",
       "\n",
       "     ratio_sentencestart_uppercase  \n",
       "0                         0.016981  \n",
       "1                         0.823698  \n",
       "2                        -0.655283  \n",
       "3                        -0.655283  \n",
       "4                        -1.887767  \n",
       "..                             ...  \n",
       "245                       3.042169  \n",
       "246                       3.042169  \n",
       "247                       3.042169  \n",
       "248                       3.042169  \n",
       "249                       3.042169  \n",
       "\n",
       "[250 rows x 82 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_features_tfidf = combined_features.transform(df_gpt['text'])\n",
    "gpt_features_combined = hstack([gpt_features_tfidf, csr_matrix(gpt_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'M': 109, 'F': 141})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_pred = model.predict(gpt_features_combined)\n",
    "Counter(gpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_features_tfidf = combined_features.transform(df_gemini['text'])\n",
    "gemini_features_combined = hstack([gemini_features_tfidf, csr_matrix(gemini_features_scaled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'F': 67, 'M': 70})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_pred = model.predict(gemini_features_combined)\n",
    "Counter(gemini_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
